{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e22a5b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_dict = {\n",
    "#     \"data\": {\n",
    "#         \"raw_data_root\": \"/home/jovyan/CHJ/Mol-LLM_Custom/dataset/real_train\",\n",
    "#         \"data_tag\": \"3.3M_0415\",\n",
    "#         \"tasks\": [\"reagent_prediction\"],\n",
    "#     },\n",
    "#     \"gnn\": {\n",
    "#         \"gnn_type\": \"gine_tokengt\",\n",
    "#         \"gnn_hidden_dim\": 1024,\n",
    "#         \"gine\": {\n",
    "#             \"gnn_hidden_dim\": 1024,\n",
    "#             \"gin_num_layers\": 5,\n",
    "#             \"drop_ratio\": 0.0,\n",
    "#             \"used_gnn_layer\": -1,\n",
    "#             \"gnn_jk\": \"last\",\n",
    "#             \"graph_encoder_ckpt\": \"/home/jovyan/CHJ/Mol-LLM_Custom/checkpoint/Custom/mol-llm.ckpt\",\n",
    "#             \"gnn_type\": \"gine\",\n",
    "#         },\n",
    "#         \"tokengt\": {\n",
    "#             \"input_feat_dim\": 9,\n",
    "#             \"gnn_hidden_dim\": 1024,\n",
    "#             \"num_layers\": 5,\n",
    "#             \"num_heads\": 8,\n",
    "#             \"method\": \"laplacian\",\n",
    "#             \"d_p\": 64,\n",
    "#             \"d_e\": 64,\n",
    "#             \"use_graph_token\": True,\n",
    "#             \"max_position_embeddings\": 102,\n",
    "#             \"graph_encoder_ckpt\": \"/home/jovyan/CHJ/Mol-LLM_Custom/checkpoint/Custom/mol-llm.ckpt\",\n",
    "#             \"gnn_type\": \"tokengt\",\n",
    "#         },\n",
    "#     },\n",
    "#     \"trainer\": {\n",
    "#         \"bert_hidden_dim\": 768,\n",
    "#         \"bert_name\": \"scibert\",\n",
    "#         \"cross_attention_freq\": 2,\n",
    "#         \"num_query_token\": 32,\n",
    "#         \"bert_num_hidden_layers\": 5,\n",
    "#         \"projector_type\": \"qformer\",\n",
    "#         \"llm_model\": \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "#         \"tune_llm\": \"lora\",\n",
    "#         \"peft_config\": None,\n",
    "#         \"peft_dir\": \"\",\n",
    "#         \"load_in_8bit\": False,\n",
    "#         \"lora_r\": 64,\n",
    "#         \"lora_alpha\": 32,\n",
    "#         \"lora_dropout\": 0.1,\n",
    "#         \"selfies_token_path\": \"Mol-LLM_Custom/model/selfies_dict.txt\",\n",
    "#         \"add_selfies_tokens\": True,\n",
    "#         \"prompt\": \"[START_I_SMILES]{}[END_I_SMILES]\",\n",
    "#         \"num_beams\": 1,\n",
    "#         \"strategy_name\": None,\n",
    "#         \"accelerator\": \"gpu\",\n",
    "#         \"devices\": \"0,1,2,3,4,5,6,7\",\n",
    "#         \"precision\": \"bf16-mixed\",\n",
    "#         \"max_steps\": -1,\n",
    "#         \"max_epochs\": 12,\n",
    "#         \"every_n_epochs\": 1,\n",
    "#         \"task\": None,\n",
    "#         \"logging_dir\": \"/home/jovyan/CHJ/Mol-LLM_Custom/checkpoint/Custom\",\n",
    "#         \"llava_pretraining\": 0,\n",
    "#         \"second_stage_start_epoch\": 4,\n",
    "#         \"num_workers\": 0,\n",
    "#         \"skip_sanity_check\": False,\n",
    "#         \"total_batch_size\": 512,\n",
    "#         \"batch_size\": 8,\n",
    "#         \"inference_batch_size\": 11,\n",
    "#         \"truncation\": 1,\n",
    "#         \"padding\": \"max_length\",\n",
    "#         \"max_length\": 512,\n",
    "#         \"inference_max_length\": 512,\n",
    "#         \"gen_max_len\": 256,\n",
    "#         \"min_len\": 8,\n",
    "#         \"apply_sequence_packing\": False,\n",
    "#         \"max_packing_size\": -1,\n",
    "#         \"weight_decay\": 0.05,\n",
    "#         \"min_lr\": 1e-05,\n",
    "#         \"init_lr\": 0.0001,\n",
    "#         \"warmup_lr\": 1e-05,\n",
    "#         \"warmup_epochs\": 0.25,\n",
    "#         \"scheduler\": \"linear_warmup_cosine_lr\",\n",
    "#         \"optimizer\": \"adamw\",\n",
    "#         \"log_every_n_steps\": 50,\n",
    "#         \"gradient_clip_val\": 0.5,\n",
    "#         \"val_check_interval\": 0.5,\n",
    "#         \"test_on_trainset\": False,\n",
    "#         \"mol_representation\": \"string+graph\",\n",
    "#         \"log_attn_score\": True,\n",
    "#         \"eval_modality_util\": None,\n",
    "#         \"tune_gnn\": True,\n",
    "#         \"train_molpo\": False,\n",
    "#         \"eval_molpo\": False,\n",
    "#         \"find_unused_parameters\": False,\n",
    "#         \"selfies_enumeration\": False,\n",
    "#         \"isomericSmiles\": False,\n",
    "#         \"canonical\": False,\n",
    "#         \"allHsExplicit\": False,\n",
    "#     },\n",
    "#     \"filename\": \"debugging\",\n",
    "#     \"seed\": 42,\n",
    "#     \"mode\": \"ft\",\n",
    "#     \"wandb_entity\": \"hj_ai\",\n",
    "#     \"wandb_project\": \"mol-llm\",\n",
    "#     \"wandb_log_freq\": 100,\n",
    "#     \"wandb_id\": None,\n",
    "#     \"debug\": False,\n",
    "#     \"ckpt_path\": None,\n",
    "#     \"pretrained_ckpt_path\": None,\n",
    "#     \"shuffle_selfies\": False,\n",
    "#     \"shuffle_graph\": False,\n",
    "#     \"process_disjoint\": True,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83444577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/miniconda3/envs/MolDA_CHJ/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/home/jovyan/miniconda3/envs/MolDA_CHJ/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/jovyan/miniconda3/envs/MolDA_CHJ/lib/python3.10/site-packages/outdated/__init__.py:36: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n",
      "WARNING:root:The OGB package is out of date. Your version is 1.3.5, while the latest version is 1.3.6.\n",
      "/home/jovyan/miniconda3/envs/MolDA_CHJ/lib/python3.10/site-packages/fairscale/experimental/nn/offload.py:19: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  return torch.cuda.amp.custom_fwd(orig_func)  # type: ignore\n",
      "/home/jovyan/miniconda3/envs/MolDA_CHJ/lib/python3.10/site-packages/fairscale/experimental/nn/offload.py:30: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  return torch.cuda.amp.custom_bwd(orig_func)  # type: ignore\n",
      "/home/jovyan/miniconda3/envs/MolDA_CHJ/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'test_CHJ.yaml': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Model...\n",
      "{'data': {'raw_data_root': '/home/jovyan/CHJ/Mol-LLM_Custom/dataset/real_train', 'data_tag': '3.3M_0415', 'tasks': ['reagent_prediction']}, 'gnn': {'gnn_type': 'gine_tokengt', 'gnn_hidden_dim': 1024, 'gine': {'gnn_hidden_dim': 1024, 'gin_num_layers': 5, 'drop_ratio': 0.0, 'used_gnn_layer': -1, 'gnn_jk': 'last', 'graph_encoder_ckpt': '/home/jovyan/CHJ/Mol-LLM_Custom/checkpoint/Custom/mol-llm.ckpt', 'gnn_type': 'gine'}, 'tokengt': {'input_feat_dim': 9, 'gnn_hidden_dim': 1024, 'num_layers': 5, 'num_heads': 8, 'method': 'laplacian', 'd_p': 64, 'd_e': 64, 'use_graph_token': True, 'max_position_embeddings': 102, 'graph_encoder_ckpt': '/home/jovyan/CHJ/Mol-LLM_Custom/checkpoint/Custom/mol-llm.ckpt', 'gnn_type': 'tokengt'}}, 'trainer': {'bert_hidden_dim': 768, 'bert_name': 'scibert', 'cross_attention_freq': 2, 'num_query_token': 32, 'bert_num_hidden_layers': 5, 'projector_type': 'qformer', 'llm_model': 'mistralai/Mistral-7B-Instruct-v0.3', 'tune_llm': 'lora', 'peft_config': None, 'peft_dir': '', 'load_in_8bit': False, 'lora_r': 64, 'lora_alpha': 32, 'lora_dropout': 0.1, 'selfies_token_path': 'Mol-LLM_Custom/model/selfies_dict.txt', 'add_selfies_tokens': True, 'prompt': '[START_I_SMILES]{}[END_I_SMILES]', 'num_beams': 1, 'strategy_name': None, 'accelerator': 'gpu', 'devices': '0,1,2,3,4,5,6,7', 'precision': 'bf16-mixed', 'max_steps': -1, 'max_epochs': 12, 'every_n_epochs': 1, 'task': None, 'logging_dir': '/home/jovyan/CHJ/Mol-LLM_Custom/checkpoint/Custom', 'llava_pretraining': 0, 'second_stage_start_epoch': 4, 'num_workers': 0, 'skip_sanity_check': False, 'total_batch_size': 512, 'batch_size': 8, 'inference_batch_size': 11, 'truncation': 1, 'padding': 'max_length', 'max_length': 512, 'inference_max_length': 512, 'gen_max_len': 256, 'min_len': 8, 'apply_sequence_packing': False, 'max_packing_size': -1, 'weight_decay': 0.05, 'min_lr': 1e-05, 'init_lr': 0.0001, 'warmup_lr': 1e-05, 'warmup_epochs': 0.25, 'scheduler': 'linear_warmup_cosine_lr', 'optimizer': 'adamw', 'log_every_n_steps': 50, 'gradient_clip_val': 0.5, 'val_check_interval': 0.5, 'test_on_trainset': False, 'mol_representation': 'string+graph', 'log_attn_score': True, 'eval_modality_util': None, 'tune_gnn': True, 'train_molpo': False, 'eval_molpo': False, 'find_unused_parameters': False, 'selfies_enumeration': False, 'isomericSmiles': False, 'canonical': False, 'allHsExplicit': False}, 'filename': 'debugging', 'seed': 42, 'mode': 'ft', 'wandb_entity': 'hj_ai', 'wandb_project': 'mol-llm', 'wandb_log_freq': 100, 'wandb_id': None, 'debug': False, 'ckpt_path': None, 'pretrained_ckpt_path': None, 'shuffle_selfies': False, 'shuffle_graph': False, 'process_disjoint': True, 'bert_hidden_dim': 768, 'bert_name': 'scibert', 'cross_attention_freq': 2, 'num_query_token': 32, 'bert_num_hidden_layers': 5, 'projector_type': 'qformer', 'llm_model': 'mistralai/Mistral-7B-Instruct-v0.3', 'tune_llm': 'lora', 'peft_config': None, 'peft_dir': '', 'load_in_8bit': False, 'lora_r': 64, 'lora_alpha': 32, 'lora_dropout': 0.1, 'selfies_token_path': '/home/jovyan/CHJ/Mol-LLM_Custom/model/selfies_dict.txt', 'add_selfies_tokens': True, 'prompt': '[START_I_SMILES]{}[END_I_SMILES]', 'num_beams': 1, 'strategy_name': None, 'accelerator': 'gpu', 'devices': '0,1,2,3,4,5,6,7', 'precision': 'bf16-mixed', 'max_steps': -1, 'max_epochs': 12, 'every_n_epochs': 1, 'task': None, 'logging_dir': '/home/jovyan/CHJ/Mol-LLM_Custom/checkpoint/Custom', 'llava_pretraining': 0, 'second_stage_start_epoch': 4, 'num_workers': 0, 'skip_sanity_check': False, 'total_batch_size': 512, 'batch_size': 8, 'inference_batch_size': 11, 'truncation': 1, 'padding': 'max_length', 'max_length': 512, 'inference_max_length': 512, 'gen_max_len': 256, 'min_len': 8, 'apply_sequence_packing': False, 'max_packing_size': -1, 'weight_decay': 0.05, 'min_lr': 1e-05, 'init_lr': 0.0001, 'warmup_lr': 1e-05, 'warmup_epochs': 0.25, 'scheduler': 'linear_warmup_cosine_lr', 'optimizer': 'adamw', 'log_every_n_steps': 50, 'gradient_clip_val': 0.5, 'val_check_interval': 0.5, 'test_on_trainset': False, 'mol_representation': 'string+graph', 'log_attn_score': True, 'eval_modality_util': None, 'tune_gnn': True, 'train_molpo': False, 'eval_molpo': False, 'find_unused_parameters': False, 'selfies_enumeration': False, 'isomericSmiles': False, 'canonical': False, 'allHsExplicit': False, 'gnn_type': 'gine_tokengt', 'gnn_hidden_dim': 1024, 'gine': {'gnn_hidden_dim': 1024, 'gin_num_layers': 5, 'drop_ratio': 0.0, 'used_gnn_layer': -1, 'gnn_jk': 'last', 'graph_encoder_ckpt': '/home/jovyan/CHJ/Mol-LLM_Custom/checkpoint/Custom/mol-llm.ckpt', 'gnn_type': 'gine'}, 'tokengt': {'input_feat_dim': 9, 'gnn_hidden_dim': 1024, 'num_layers': 5, 'num_heads': 8, 'method': 'laplacian', 'd_p': 64, 'd_e': 64, 'use_graph_token': True, 'max_position_embeddings': 102, 'graph_encoder_ckpt': '/home/jovyan/CHJ/Mol-LLM_Custom/checkpoint/Custom/mol-llm.ckpt', 'gnn_type': 'tokengt'}}  - args\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file tokenizer.model from cache at /home/jovyan/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/c170c708c41dac9275d15a8fff4eca08d52bab71/tokenizer.model\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/jovyan/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/c170c708c41dac9275d15a8fff4eca08d52bab71/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/jovyan/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/c170c708c41dac9275d15a8fff4eca08d52bab71/tokenizer_config.json\n",
      "loading file tokenizer.json from cache at /home/jovyan/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/c170c708c41dac9275d15a8fff4eca08d52bab71/tokenizer.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 2944 selfies tokens to the tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/c170c708c41dac9275d15a8fff4eca08d52bab71/config.json\n",
      "Model config MistralConfig {\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.44.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/jovyan/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/c170c708c41dac9275d15a8fff4eca08d52bab71/model.safetensors.index.json\n",
      "Instantiating MistralForCausalLM_custom model under default dtype torch.bfloat16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  4.19it/s]\n",
      "All model checkpoint weights were used when initializing MistralForCausalLM_custom.\n",
      "\n",
      "All the weights of MistralForCausalLM_custom were initialized from the model checkpoint at mistralai/Mistral-7B-Instruct-v0.3.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM_custom for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /home/jovyan/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/c170c708c41dac9275d15a8fff4eca08d52bab71/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2\n",
      "}\n",
      "\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 35745. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 167,772,160 || all params: 7,440,183,296 || trainable%: 2.2549\n",
      "/home/jovyan/CHJ/Mol-LLM_Custom/checkpoint/Custom/mol-llm.ckpt -args.gine.graph_encoder_ckpt\n",
      "load graph encoder from /home/jovyan/CHJ/Mol-LLM_Custom/checkpoint/Custom/mol-llm.ckpt\n",
      "load graph encoder from /home/jovyan/CHJ/Mol-LLM_Custom/checkpoint/Custom/mol-llm.ckpt\n",
      "bert load scibert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.44.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/jovyan/.cache/huggingface/hub/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertLMHeadModel: ['bert.embeddings.token_type_embeddings.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.0.intermediate_query.dense.bias', 'bert.encoder.layer.0.intermediate_query.dense.weight', 'bert.encoder.layer.0.output_query.LayerNorm.bias', 'bert.encoder.layer.0.output_query.LayerNorm.weight', 'bert.encoder.layer.0.output_query.dense.bias', 'bert.encoder.layer.0.output_query.dense.weight', 'bert.encoder.layer.1.intermediate_query.dense.bias', 'bert.encoder.layer.1.intermediate_query.dense.weight', 'bert.encoder.layer.1.output_query.LayerNorm.bias', 'bert.encoder.layer.1.output_query.LayerNorm.weight', 'bert.encoder.layer.1.output_query.dense.bias', 'bert.encoder.layer.1.output_query.dense.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.2.intermediate_query.dense.bias', 'bert.encoder.layer.2.intermediate_query.dense.weight', 'bert.encoder.layer.2.output_query.LayerNorm.bias', 'bert.encoder.layer.2.output_query.LayerNorm.weight', 'bert.encoder.layer.2.output_query.dense.bias', 'bert.encoder.layer.2.output_query.dense.weight', 'bert.encoder.layer.3.intermediate_query.dense.bias', 'bert.encoder.layer.3.intermediate_query.dense.weight', 'bert.encoder.layer.3.output_query.LayerNorm.bias', 'bert.encoder.layer.3.output_query.LayerNorm.weight', 'bert.encoder.layer.3.output_query.dense.bias', 'bert.encoder.layer.3.output_query.dense.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.4.intermediate_query.dense.bias', 'bert.encoder.layer.4.intermediate_query.dense.weight', 'bert.encoder.layer.4.output_query.LayerNorm.bias', 'bert.encoder.layer.4.output_query.LayerNorm.weight', 'bert.encoder.layer.4.output_query.dense.bias', 'bert.encoder.layer.4.output_query.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generation config file not found, using a generation config created from the model config.\n",
      "loading file vocab.txt from cache at /home/jovyan/.cache/huggingface/hub/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading file tokenizer.json from cache at None\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.44.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "/home/jovyan/miniconda3/envs/MolDA_CHJ/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1394657/3226601686.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(ckpt_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from /home/jovyan/CHJ/Mol-LLM_Custom/checkpoint/Custom/mol-llm.ckpt...\n",
      "Missing keys: 291\n",
      "Unexpected keys: 0\n",
      "Model loaded successfully!\n",
      "Prompt: <s>[INST] You are a helpful assistant for molecular chemistry, to address tasks including molecular property classification, molecular property regression, chemical reaction prediction, molecule captioning, molecule generation. \n",
      "\n",
      "Please provide the HOMO energy value for this molecule: <SELFIES> [C][O][C@H1][C][Branch1][C][C][=C][C@H1][C][C@H1][Ring1][Ring1][Ring1][#Branch1] </SELFIES><GRAPH><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol></GRAPH> [/INST]\n",
      "Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/miniconda3/envs/MolDA_CHJ/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "WARNING:model.blip2_mistral:Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Input SELFIES: [C][O][C@H1][C][Branch1][C][C][=C][C@H1][C][C@H1][Ring1][Ring1][Ring1][#Branch1]\n",
      "Prediction: [=As] [Ge] [86Zr]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "import selfies as sf\n",
    "from torch_geometric.data import Data, Batch\n",
    "from model.blip2_stage3 import Blip2Stage3\n",
    "from ogb.utils import smiles2graph\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. Config & Setup (stage3.py와 동일한 환경 구성)\n",
    "# ==============================================================================\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "\n",
    "# config 경로는 실제 환경에 맞게 수정해주세요\n",
    "with initialize(version_base=None, config_path=\"configs\"):\n",
    "    cfg = compose(config_name=\"test_CHJ.yaml\")\n",
    "\n",
    "# Config 구조 맞추기 (stage3.py의 main 함수 로직 반영)\n",
    "OmegaConf.set_struct(cfg, False)\n",
    "if \"trainer\" in cfg: cfg = OmegaConf.merge(cfg, cfg.trainer)\n",
    "if \"gnn\" in cfg: cfg = OmegaConf.merge(cfg, cfg.gnn)\n",
    "\n",
    "# 경로 설정 (사용자 환경에 맞게 수정)\n",
    "root_dir = \"/home/jovyan/CHJ/Mol-LLM_Custom\"\n",
    "ckpt_path = os.path.join(root_dir, \"checkpoint/Custom/mol-llm.ckpt\") \n",
    "token_path = os.path.join(root_dir, \"model/selfies_dict.txt\")\n",
    "\n",
    "# GNN 체크포인트 경로 설정 (중요)\n",
    "if hasattr(cfg, \"gine\"): cfg.gine.graph_encoder_ckpt = ckpt_path\n",
    "if hasattr(cfg, \"tokengt\"): cfg.tokengt.graph_encoder_ckpt = ckpt_path\n",
    "cfg.selfies_token_path = token_path\n",
    "OmegaConf.set_struct(cfg, True)\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. 모델 초기화 및 로드 (여기가 핵심입니다!)\n",
    "# ==============================================================================\n",
    "print(\"Initializing Model...\")\n",
    "# 1. 모델 껍데기 생성 (stage3.py와 동일)\n",
    "model = Blip2Stage3(cfg)\n",
    "\n",
    "print(f\"Loading weights from {ckpt_path}...\")\n",
    "# 2. 체크포인트 파일 읽기\n",
    "checkpoint = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "state_dict = checkpoint[\"state_dict\"] if \"state_dict\" in checkpoint else checkpoint\n",
    "\n",
    "# 3. [중요] 키 변경 없이 그대로 로드합니다.\n",
    "# Blip2Stage3는 내부에 self.blip2model을 가지고 있으므로, \n",
    "# 체크포인트의 'blip2model.xxx' 키와 정확히 매칭됩니다.\n",
    "missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "print(f\"Missing keys: {len(missing_keys)}\")\n",
    "print(f\"Unexpected keys: {len(unexpected_keys)}\")\n",
    "# missing_keys에 'blip2model.llm_model.lm_head.weight' 등이 없어야 정상입니다.\n",
    "\n",
    "# 4. 장치 이동 및 정밀도 설정\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.eval()\n",
    "model.to(device)\n",
    "# 학습 때 bfloat16을 썼다면 여기서도 맞춰줍니다.\n",
    "model.to(torch.bfloat16) \n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. 데이터 전처리 (Input 준비)\n",
    "# ==============================================================================\n",
    "tokenizer = model.blip2model.llm_tokenizer\n",
    "tokenizer.padding_side = \"left\"\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "mol_token_id = tokenizer.mol_token_id\n",
    "mol_token = \"<mol>\"\n",
    "num_query_tokens = 32\n",
    "\n",
    "# 사용자 입력 예시\n",
    "input_selfies = \"[C][O][C@H1][C][Branch1][C][C][=C][C@H1][C][C@H1][Ring1][Ring1][Ring1][#Branch1]\"\n",
    "instruction_template = \"Please provide the HOMO energy value for this molecule: <INPUT>\"\n",
    "system_prompt = \"You are a helpful assistant for molecular chemistry, to address tasks including molecular property classification, molecular property regression, chemical reaction prediction, molecule captioning, molecule generation.\"\n",
    "\n",
    "# Graph 변환 함수\n",
    "def smiles2data(smiles):\n",
    "    try:\n",
    "        graph = smiles2graph(smiles)\n",
    "        x = torch.from_numpy(graph[\"node_feat\"]).long()\n",
    "        edge_index = torch.from_numpy(graph[\"edge_index\"]).long()\n",
    "        edge_attr = torch.from_numpy(graph[\"edge_feat\"]).long()\n",
    "        return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# 데이터 생성\n",
    "smiles = sf.decoder(input_selfies)\n",
    "graph = smiles2data(smiles)\n",
    "\n",
    "# 배치 차원 추가 및 이동\n",
    "graph_batch = Batch.from_data_list([graph]).to(device)\n",
    "# 모델이 두 개의 그래프 입력을 요구하는 경우 (Stage3 구조에 따라 다름, 보통 하나면 됨)\n",
    "# 만약 에러가 나면 model.blip2model.generate의 graphs 인자를 확인해야 함. \n",
    "# 여기서는 safe하게 튜플로 묶어서 전달 준비\n",
    "graphs_input = (graph_batch, graph_batch) \n",
    "\n",
    "# 프롬프트 구성\n",
    "formatted_selfies = f\"<SELFIES> {input_selfies} </SELFIES>\"\n",
    "# <mol> 토큰을 32개 채워넣어 그래프 정보를 위한 자리를 만듭니다.\n",
    "graph_placeholder = \"<GRAPH>\" + mol_token * num_query_tokens + \"</GRAPH>\"\n",
    "input_mol_string = formatted_selfies + graph_placeholder\n",
    "final_instruction = instruction_template.replace(\"<INPUT>\", input_mol_string)\n",
    "\n",
    "full_prompt = f\"<s>[INST] {system_prompt} \\n\\n{final_instruction} [/INST]\"\n",
    "print(f\"Prompt: {full_prompt}\")\n",
    "\n",
    "# 토크나이징\n",
    "inputs = tokenizer(\n",
    "    [full_prompt], \n",
    "    return_tensors=\"pt\", \n",
    "    add_special_tokens=False, \n",
    "    padding=True\n",
    ")\n",
    "input_ids = inputs.input_ids.to(device)\n",
    "attention_mask = inputs.attention_mask.to(device)\n",
    "is_mol_token = (input_ids == mol_token_id)\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. Inference 실행\n",
    "# ==============================================================================\n",
    "print(\"Generating...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    # autocast를 사용하여 dtype 불일치 문제 방지\n",
    "    with torch.amp.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "        outputs = model.blip2model.generate(\n",
    "            graphs=graphs_input,  # 모델 정의에 따라 graphs가 리스트나 튜플일 수 있음\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            is_mol_token=is_mol_token,\n",
    "            num_beams=5,\n",
    "            max_length=256,\n",
    "            min_length=1,\n",
    "            do_sample=False,\n",
    "            repetition_penalty=1.0\n",
    "        )\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. 결과 확인\n",
    "# ==============================================================================\n",
    "raw_prediction = outputs.predictions[0]\n",
    "clean_prediction = raw_prediction.replace(tokenizer.pad_token, \"\").replace(\"</s>\", \"\").strip()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Input SELFIES: {input_selfies}\")\n",
    "print(f\"Prediction: {clean_prediction}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91da0410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'alchemy_homo',\n",
       " 'x': [[5, 0, 4, 5, 3, 0, 2, 0, 0],\n",
       "  [7, 0, 2, 5, 0, 0, 2, 0, 0],\n",
       "  [5, 2, 4, 5, 1, 0, 2, 0, 1],\n",
       "  [5, 2, 4, 5, 1, 0, 2, 0, 1],\n",
       "  [5, 0, 4, 5, 2, 0, 2, 0, 1],\n",
       "  [5, 2, 4, 5, 1, 0, 2, 0, 1],\n",
       "  [5, 0, 3, 5, 1, 0, 1, 0, 1],\n",
       "  [5, 0, 3, 5, 0, 0, 1, 0, 1],\n",
       "  [5, 0, 4, 5, 3, 0, 2, 0, 0]],\n",
       " 'edge_index': [[0, 1, 1, 2, 2, 3, 2, 7, 3, 4, 3, 5, 4, 5, 5, 6, 6, 7, 7, 8],\n",
       "  [1, 0, 2, 1, 3, 2, 7, 2, 4, 3, 5, 3, 5, 4, 6, 5, 7, 6, 8, 7]],\n",
       " 'edge_attr': [[0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [1, 0, 0],\n",
       "  [1, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0]],\n",
       " 'additional_x': [[5, 0, 4, 5, 3, 0, 2, 0, 0],\n",
       "  [7, 0, 2, 5, 0, 0, 2, 0, 0],\n",
       "  [5, 2, 4, 5, 1, 0, 2, 0, 1],\n",
       "  [5, 2, 4, 5, 1, 0, 2, 0, 1],\n",
       "  [5, 0, 4, 5, 2, 0, 2, 0, 1],\n",
       "  [5, 2, 4, 5, 1, 0, 2, 0, 1],\n",
       "  [5, 0, 3, 5, 1, 0, 1, 0, 1],\n",
       "  [5, 0, 3, 5, 0, 0, 1, 0, 1],\n",
       "  [5, 0, 4, 5, 3, 0, 2, 0, 0]],\n",
       " 'additional_edge_index': [[0,\n",
       "   1,\n",
       "   1,\n",
       "   2,\n",
       "   2,\n",
       "   3,\n",
       "   2,\n",
       "   7,\n",
       "   3,\n",
       "   4,\n",
       "   3,\n",
       "   5,\n",
       "   4,\n",
       "   5,\n",
       "   5,\n",
       "   6,\n",
       "   6,\n",
       "   7,\n",
       "   7,\n",
       "   8],\n",
       "  [1, 0, 2, 1, 3, 2, 7, 2, 4, 3, 5, 3, 5, 4, 6, 5, 7, 6, 8, 7]],\n",
       " 'additional_edge_attr': [[0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [1, 0, 0],\n",
       "  [1, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0]],\n",
       " 'input_mol_string': '<SELFIES> [C][O][C@H1][C][Branch1][C][C][=C][C@H1][C][C@H1][Ring1][Ring1][Ring1][#Branch1] </SELFIES>',\n",
       " 'prompt_text': '<s>[INST] You are a helpful assistant for molecular chemistry, to address tasks including molecular property classification, molecular property regression, chemical reaction prediction, molecule captioning, molecule generation. \\n\\nPlease provide the HOMO energy value for this molecule: <SELFIES> [C][O][C@H1][C][Branch1][C][C][=C][C@H1][C][C@H1][Ring1][Ring1][Ring1][#Branch1] </SELFIES><GRAPH><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol></GRAPH>. [/INST] ',\n",
       " 'target_text': '<FLOAT> <|-|><|0|><|.|><|2|><|1|><|7|><|5|> </FLOAT> </s>'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "data = load_from_disk('/home/jovyan/CHJ/Mol-LLM_Custom/checkpoint/mol-llm_testset')\n",
    "\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545c138a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MolDA_CHJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
