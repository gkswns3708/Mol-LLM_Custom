import faulthandler
faulthandler.enable()
import os
import torch
import argparse
import warnings
import pytorch_lightning as pl
from pytorch_lightning import Trainer, strategies
from pytorch_lightning.callbacks import Callback, ModelCheckpoint
from pytorch_lightning.loggers import CSVLogger, WandbLogger, TensorBoardLogger
from data_module import Stage3DM
from model.blip2_stage3 import Blip2Stage3
import json
import hydra
from omegaconf import OmegaConf, DictConfig
from hydra.core.hydra_config import HydraConfig 
from datetime import timedelta
import wandb
import nltk
from pprint import pprint
from datetime import datetime
nltk.download("wordnet")

os.environ["OPENBLAS_NUM_THREADS"] = "1"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# for pyg bug
warnings.filterwarnings(
    "ignore", category=UserWarning, message="TypedStorage is deprecated"
)
warnings.filterwarnings("ignore", message=r".*Skipped loading .*")
warnings.filterwarnings("ignore", message=r".*No normalization for .*")
# for A5000 gpus
torch.set_float32_matmul_precision(
    "medium"
)  # can be medium (bfloat16), high (tensorfloat32), highest (float32)

class SaveInitCheckpointCallback(Callback):
    def __init__(self, filename="initial_checkpoint.ckpt"):
        self.filename = filename

    def on_fit_start(self, trainer, pl_module):
        # ì €ìž¥ ê²½ë¡œ ìƒì„±
        save_path = os.path.join(trainer.logger.log_dir, self.filename)
        print(f"\n[INFO] Saving initial checkpoint before training/validation to: {save_path}")
        trainer.save_checkpoint(save_path)
        
class MyDDPStrategy(strategies.DDPStrategy):
    def __init__(
        self,
        find_unused_parameters=False,
        start_method="spawn",
        timeout=timedelta(minutes=90),
    ): 
        super().__init__(
            find_unused_parameters=find_unused_parameters,
            start_method=start_method,
            timeout=timeout,
        )

    def load_model_state_dict(self, checkpoint, strict=False):
        assert self.lightning_module is not None
        self.lightning_module.load_state_dict(checkpoint["state_dict"], strict=strict)


def print_training_config_report(cfg, model):
    """í†µí•©ëœ í•™ìŠµ ì„¤ì • ë° íŒŒë¼ë¯¸í„° ë¦¬í¬íŠ¸ ì¶œë ¥"""

    # íŒŒë¼ë¯¸í„° ë¶„ì„
    all_params = 0
    trainable_params = 0
    component_params = {
        'lora': 0,
        'embedding': 0,
        'lm_head': 0,
        'qformer': 0,
        'graph': 0,
        'other': 0
    }

    trainable_layers = {
        'lora_modules': set(),
        'embedding_layers': [],
        'lm_head_layers': [],
        'qformer_layers': [],
        'graph_layers': [],
        'other_layers': []
    }

    for name, param in model.named_parameters():
        all_params += param.numel()
        if param.requires_grad:
            trainable_params += param.numel()

            # ì»´í¬ë„ŒíŠ¸ë³„ ë¶„ë¥˜
            if 'lora' in name.lower():
                component_params['lora'] += param.numel()
                # LoRA ëª¨ë“ˆëª… ì¶”ì¶œ (ì˜ˆ: blocks.0.q_proj)
                module_name = name.split('.lora_')[0] if '.lora_' in name else name
                base_module = '.'.join(module_name.split('.')[-3:])  # ë§ˆì§€ë§‰ 3ë ˆë²¨ë§Œ
                trainable_layers['lora_modules'].add(base_module)
            elif any(x in name.lower() for x in ['wte', 'embed_tokens', 'word_embeddings']):
                component_params['embedding'] += param.numel()
                trainable_layers['embedding_layers'].append(name.split('.')[-2] + '.' + name.split('.')[-1])
            elif any(x in name.lower() for x in ['ff_out', 'lm_head']) and 'blocks' not in name:
                component_params['lm_head'] += param.numel()
                trainable_layers['lm_head_layers'].append(name.split('.')[-2] + '.' + name.split('.')[-1])
            elif 'qformer' in name.lower():
                component_params['qformer'] += param.numel()
                trainable_layers['qformer_layers'].append('.'.join(name.split('.')[-3:]))
            elif 'graph' in name.lower():
                component_params['graph'] += param.numel()
                trainable_layers['graph_layers'].append('.'.join(name.split('.')[-3:]))
            else:
                component_params['other'] += param.numel()
                trainable_layers['other_layers'].append('.'.join(name.split('.')[-3:]))

    # ë¦¬í¬íŠ¸ ì¶œë ¥
    print("\n" + "="*100)
    print("ðŸš€ TRAINING CONFIGURATION & PARAMETER REPORT".center(100))
    print("="*100)

    # 1. ê¸°ë³¸ ì„¤ì •
    print("\nðŸ“‹ [Configuration]")
    print(f"  Config File:        {HydraConfig.get().job.config_name}")
    print(f"  Mode:               {cfg.mode}")
    print(f"  Model:              {cfg.llm_model}")
    print(f"  Training Method:    LoRA (r={cfg.lora_r}, alpha={cfg.lora_alpha}, dropout={cfg.lora_dropout})")
    print(f"  Projector:          {cfg.projector_type}")
    print(f"  Precision:          {cfg.precision}")
    print(f"  Devices:            {cfg.devices}")
    print(f"  Seed:               {cfg.seed}")

    # 2. í•™ìŠµ ì„¤ì •
    print("\nâš™ï¸  [Training Settings]")
    print(f"  Max Epochs:         {cfg.max_epochs}")
    print(f"  Batch Size:         {cfg.batch_size} x {cfg.accumulate_grad_batches} (accum) = {cfg.total_batch_size} (effective)")
    print(f"  Learning Rate:      {cfg.init_lr} (init), {cfg.min_lr} (min)")
    print(f"  Warmup Steps:       {cfg.warmup_steps}")
    print(f"  Scheduler:          {cfg.scheduler}")
    print(f"  Optimizer:          {cfg.optimizer}")
    print(f"  Gradient Clip:      {cfg.gradient_clip_val}")
    print(f"  Weight Decay:       {cfg.weight_decay}")

    # 3. Checkpoint ì„¤ì •
    print("\nðŸ’¾ [Checkpoint Settings]")
    print(f"  Save Every:         {cfg.save_on_n_steps} steps")
    print(f"  Keep Top-K:         {cfg.save_top_k_checkpoints if hasattr(cfg, 'save_top_k_checkpoints') else 'All'} checkpoints")
    print(f"  Best Models:        Top {cfg.save_top_k_best if hasattr(cfg, 'save_top_k_best') else 3} (by val_loss)")
    print(f"  Directory:          {cfg.logging_dir}/{cfg.filename}")

    # 4. Resume/Pretrain ì •ë³´
    if cfg.ckpt_path or cfg.pretrained_ckpt_path:
        print("\nðŸ”„ [Resume/Pretrain]")
        if cfg.ckpt_path:
            print(f"  Resume from:        {cfg.ckpt_path}")
        if cfg.pretrained_ckpt_path:
            print(f"  Pretrained:         {cfg.pretrained_ckpt_path}")

    # 5. íŒŒë¼ë¯¸í„° í†µê³„
    print("\nðŸ“Š [Parameter Statistics]")
    print(f"  Total Parameters:   {all_params:,}")
    print(f"  Trainable:          {trainable_params:,} ({trainable_params/all_params*100:.2f}%)")
    print(f"  Frozen:             {all_params - trainable_params:,} ({(all_params - trainable_params)/all_params*100:.2f}%)")

    # 6. ì»´í¬ë„ŒíŠ¸ë³„ íŒŒë¼ë¯¸í„°
    print("\nðŸ”§ [Trainable Components Breakdown]")
    if component_params['lora'] > 0:
        print(f"  âœ… LoRA Adapters:      {component_params['lora']:>12,} params  ({len(trainable_layers['lora_modules'])} unique modules)")
    if component_params['embedding'] > 0:
        print(f"  âœ… Embeddings:         {component_params['embedding']:>12,} params  ({len(trainable_layers['embedding_layers'])} layers)")
    if component_params['lm_head'] > 0:
        print(f"  âœ… LM Head:            {component_params['lm_head']:>12,} params  ({len(trainable_layers['lm_head_layers'])} layers)")
    if component_params['qformer'] > 0:
        print(f"  âœ… Q-Former:           {component_params['qformer']:>12,} params  ({len(set(trainable_layers['qformer_layers']))} layers)")
    if component_params['graph'] > 0:
        print(f"  âœ… Graph Encoder:      {component_params['graph']:>12,} params  ({len(set(trainable_layers['graph_layers']))} layers)")
    if component_params['other'] > 0:
        print(f"  âš ï¸  Other:              {component_params['other']:>12,} params")

    # 7. ìƒì„¸ ë ˆì´ì–´ ì •ë³´ (ê°„ê²°í•˜ê²Œ)
    print("\nðŸ“ [Trainable Layer Details]")

    if trainable_layers['lora_modules']:
        lora_sample = sorted(list(trainable_layers['lora_modules']))[:3]
        print(f"  LoRA Modules:       {', '.join(lora_sample)}")
        if len(trainable_layers['lora_modules']) > 3:
            print(f"                      ... and {len(trainable_layers['lora_modules']) - 3} more")

    if trainable_layers['embedding_layers']:
        print(f"  Embedding:          {', '.join(trainable_layers['embedding_layers'])}")

    if trainable_layers['lm_head_layers']:
        print(f"  LM Head:            {', '.join(trainable_layers['lm_head_layers'])}")

    if trainable_layers['qformer_layers']:
        qformer_sample = trainable_layers['qformer_layers'][:3]
        print(f"  Q-Former:           {', '.join(qformer_sample)}")
        if len(trainable_layers['qformer_layers']) > 3:
            print(f"                      ... and {len(trainable_layers['qformer_layers']) - 3} more")

    # 8. ê²½ê³  ë©”ì‹œì§€
    if trainable_params < 10_000_000:
        print("\nâš ï¸  [WARNING] Trainable parameters are very low (< 10M)!")
        print("    â†’ Check if LoRA target modules match the model architecture")
        print("    â†’ Verify Q-Former/Graph encoder training settings")

    if component_params['lora'] == 0 and 'lora' in cfg.tune_llm.lower():
        print("\nâŒ [ERROR] LoRA is enabled but no LoRA parameters found!")
        print("    â†’ Check lora_config_llada.json target_modules")

    print("\n" + "="*100 + "\n")


@hydra.main(config_path="configs", config_name="train_llada.yaml", version_base=None)
def main(cfg):
    cfg = flatten_dictconfig(cfg)
    pl.seed_everything(cfg.seed)
    model = Blip2Stage3(cfg)

    # í†µí•© ë¦¬í¬íŠ¸ ì¶œë ¥
    print_training_config_report(cfg, model)
        
    # when resuming training, load the current epoch information and argparse to datamodule
    if cfg.ckpt_path is not None:
        ckpt = torch.load(cfg.ckpt_path, map_location="cpu", weights_only=False)
        cfg.current_epoch = ckpt["epoch"]
        del ckpt
    else:
        cfg.current_epoch = 0

    # datamodule
    dm = Stage3DM(
        mode=cfg.mode,
        num_workers=cfg.num_workers,
        tokenizer=model.blip2model.llm_tokenizer,
        args=cfg,
    )
    #! í•´ë‹¹ ì•„ëž˜ ì½”ë“œì˜ ì˜ë„ë¥¼ í•´ê²°í•˜ê³  ì£¼ì„ ì—¬ë¶€ ê²°ì •í•˜ê¸°
    # print("\n" + "="*50)
    # print("[DEBUG] Inspecting one batch from Dataloader...")
    # try:
    #     # ì‹¤í–‰ ëª¨ë“œ(mode)ì— ë”°ë¼ ì ì ˆí•œ dataloader ì„ íƒ
    #     if cfg.mode == "test":
    #         debug_loader = dm.test_dataloader()
    #         print("[DEBUG] Using Test Dataloader")
    #     else:
    #         debug_loader = dm.train_dataloader()
    #         print("[DEBUG] Using Train Dataloader")
        
    #     # ë°°ì¹˜ í•˜ë‚˜ ê°€ì ¸ì˜¤ê¸°
    #     batch = next(iter(debug_loader))
        
    #     print(f"[DEBUG] Batch Keys: {list(batch.keys())}")
        
    #     # í‚¤ë³„ ê°’ ì¶œë ¥
    #     for key, value in batch.items():
    #         print(f"\n[Key]: {key}")
    #         if isinstance(value, torch.Tensor):
    #             pprint(f"  Type: Tensor")
    #             pprint(f"  Shape: {value.shape}")
    #             pprint(f"  Values:\n{value}")
    #         else:
    #             pprint(f"  Type: {type(value)}")
    #             pprint(f"  Values:\n{value}")
                
    # except Exception as e:
    #     print(f"[DEBUG] Failed to inspect dataloader: {e}")
    # print("="*50 + "\n")
    # [End] Dataloader Inspection Code
    callbacks = []
    today_date = datetime.now().strftime("%Y%m%d")

    # 1. [Step-based Checkpoint] ì •ê¸°ì ìœ¼ë¡œ stepë§ˆë‹¤ ì €ìž¥
    # save_top_kë¥¼ ì‚¬ìš©í•˜ë©´ monitorê°€ í•„ìš”í•˜ë¯€ë¡œ, -1(ëª¨ë‘ ì €ìž¥)ì¼ ë•Œë§Œ monitor ì—†ì´ ì‚¬ìš©
    save_top_k_checkpoints = cfg.save_top_k_checkpoints if hasattr(cfg, 'save_top_k_checkpoints') else -1

    train_checkpoint_callback = ModelCheckpoint(
        dirpath=os.path.join(cfg.logging_dir, cfg.filename),
        filename="{epoch:02d}-{step:06d}-train", # íŒŒì¼ëª…ì— epochì™€ step ëª¨ë‘ í‘œì‹œ
        every_n_train_steps=cfg.save_on_n_steps if cfg.save_on_n_steps > 0 else None,
        save_last=True,                      # last.ckpt (ìµœì‹  ìƒíƒœ) ì €ìž¥
        save_top_k=-1,                       # ëª¨ë‘ ì €ìž¥ (ê°œìˆ˜ ì œí•œ ì—†ìŒ)
        save_on_train_epoch_end=True         # epoch ëì—ë„ ì €ìž¥
    )
    callbacks.append(train_checkpoint_callback)

    # 2. [Best Validation Checkpoint] Validation Loss ê¸°ì¤€ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ìž¥
    best_checkpoint_callback = ModelCheckpoint(
        dirpath=os.path.join(cfg.logging_dir, cfg.filename),
        filename=f"best_{today_date}_{{epoch:02d}}_{{step:06d}}_loss={{val_total_loss:.4f}}",
        monitor="val_total_loss",  # [ì¤‘ìš”] ëª¨ë¸ì—ì„œ logí•˜ëŠ” metric ì´ë¦„ê³¼ ê°™ì•„ì•¼ í•¨
        mode="min",                # Lossë‹ˆê¹Œ ìž‘ì„ìˆ˜ë¡ ì¢‹ìŒ (min)
        save_top_k=cfg.save_top_k_best if hasattr(cfg, 'save_top_k_best') else 3,  # ìƒìœ„ Nê°œ ëª¨ë¸ ìœ ì§€
        save_last=False,
        auto_insert_metric_name=False
    )
    callbacks.append(best_checkpoint_callback)

    # 3. [Optional] Epoch ê¸°ë°˜ ì •ê¸° ì €ìž¥ (save_every_n_epochsê°€ ì„¤ì •ëœ ê²½ìš°)
    if hasattr(cfg, 'save_every_n_epochs') and cfg.save_every_n_epochs > 0:
        epoch_checkpoint_callback = ModelCheckpoint(
            dirpath=os.path.join(cfg.logging_dir, cfg.filename),
            filename="{epoch:02d}-end",
            every_n_epochs=cfg.save_every_n_epochs,
            save_top_k=-1,  # ëª¨ë“  epoch checkpoint ìœ ì§€
            save_on_train_epoch_end=True
        )
        callbacks.append(epoch_checkpoint_callback)
        print(f"[INFO] Epoch checkpoint enabled: Saving every {cfg.save_every_n_epochs} epochs")

    print(f"[INFO] Checkpoint configuration:")
    print(f"  - Save every {cfg.save_on_n_steps} steps (keep {callbacks[0].save_top_k} checkpoints)")
    print(f"  - Save top {best_checkpoint_callback.save_top_k} best validation checkpoints")
    print(f"  - Checkpoint directory: {os.path.join(cfg.logging_dir, cfg.filename)}")

    if len(cfg.devices.split(",")) > 1:
        if cfg.strategy_name == "fsdp":
            strategy = strategies.DDPFullyShardedNativeStrategy()
        elif cfg.strategy_name == "deepspeed":
            strategy = strategies.DeepSpeedStrategy(stage=3)
        else:
            strategy = MyDDPStrategy(
                find_unused_parameters=cfg.find_unused_parameters,
                start_method="spawn",
                timeout=timedelta(minutes=90),
            )
    else:
        strategy = "auto"
        cfg.devices = [eval(cfg.devices)]

    logger = CSVLogger(save_dir=os.path.join(cfg.logging_dir, cfg.filename))

    wandb_logger = WandbLogger(
        name=cfg.filename,
        project=cfg.wandb_project,
        entity=cfg.wandb_entity,
        id=cfg.wandb_id,
        resume="allow",
    )

    tb_logger = TensorBoardLogger(
        os.path.join(cfg.logging_dir, "tensorboard"),
        name=cfg.filename,
    )

    world_size = len(cfg.devices.split(",")) if "," in cfg.devices else 1
    cfg.accumulate_grad_batches = cfg.total_batch_size // cfg.batch_size // world_size
    print("accumulate_grad_batches:", cfg.accumulate_grad_batches)

    # [FIX OOM] Set PyTorch memory allocator config for better fragmentation handling
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'

    trainer_args = {
        "accelerator": cfg.accelerator,
        "devices": cfg.devices,
        "precision": cfg.precision,
        "callbacks": callbacks,
        "strategy": strategy,
        "logger": [logger, wandb_logger, tb_logger],
        "max_steps": cfg.max_steps,
        "max_epochs": cfg.max_epochs,
        "val_check_interval": cfg.val_check_interval,
        "accumulate_grad_batches": cfg.accumulate_grad_batches,
        "check_val_every_n_epoch": cfg.check_val_every_n_epoch,
        "log_every_n_steps": cfg.log_every_n_steps,
        "gradient_clip_val": cfg.gradient_clip_val,
        "num_sanity_val_steps": cfg.num_sanity_val_steps,
        "limit_val_batches": cfg.limit_val_batches if hasattr(cfg, "limit_val_batches") else 1.0,
        "enable_progress_bar": True,  # Progress bar enabled
    }

    if cfg.skip_sanity_check:
        trainer_args["num_sanity_val_steps"] = 0
    if hasattr(cfg, "profiler"):
        trainer_args["profiler"] = cfg.profiler

    trainer = Trainer(**trainer_args)

    # load pretrained model for model parameter initialization
    if cfg.pretrained_ckpt_path is not None:
        assert cfg.ckpt_path is None, "only one ckpt path should be provided"
        ckpt = torch.load(cfg.pretrained_ckpt_path, map_location="cpu", weights_only=False)
        model.load_state_dict(ckpt["state_dict"], strict=False)
        print(f"loaded pretrained model from {cfg.pretrained_ckpt_path}")

        # [CRITICAL FIX] ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ í›„ modules_to_saveë¥¼ ê°•ì œë¡œ trainable ì„¤ì •
        print("\n" + "="*70)
        print("[CHECKPOINT LOAD] Fixing modules_to_save gradients after checkpoint load...")
        model._fix_modules_to_save_gradients()
        print("="*70 + "\n")

    if cfg.mode in {"ft"}:
        # Resume ì •ë³´ ì¶œë ¥
        if cfg.ckpt_path is not None:
            print("\n" + "="*70)
            print(f"[RESUME] Resuming training from checkpoint:")
            print(f"  - Checkpoint path: {cfg.ckpt_path}")
            try:
                ckpt_info = torch.load(cfg.ckpt_path, map_location="cpu", weights_only=False)
                print(f"  - Epoch: {ckpt_info.get('epoch', 'N/A')}")
                print(f"  - Global step: {ckpt_info.get('global_step', 'N/A')}")
                if 'callbacks' in ckpt_info and 'ModelCheckpoint' in str(ckpt_info['callbacks']):
                    print(f"  - Best validation loss: {ckpt_info['callbacks'].get('ModelCheckpoint', {}).get('best_model_score', 'N/A')}")
                del ckpt_info
            except Exception as e:
                print(f"  - Could not read checkpoint info: {e}")
            print("="*70 + "\n")
        else:
            print("\n" + "="*70)
            print("[TRAINING] Starting training from scratch")
            print("="*70 + "\n")

        trainer.fit(model, datamodule=dm, ckpt_path=cfg.ckpt_path)
        outputs = trainer.test(model, datamodule=dm)
        assert "Training done"
    elif cfg.mode == "test":
        ckpt = torch.load(cfg.ckpt_path, map_location="cpu", weights_only=False)
        model.load_state_dict(ckpt["state_dict"], strict=False)
        print(f"loaded trained model from {cfg.ckpt_path}")
        outputs = trainer.test(model, datamodule=dm)
        if cfg.filename is not None:
            update_result_csv(
                logger_dir=trainer.logger.log_dir,
                outputs=outputs,
            )
        assert "Testing done"
    else:
        raise NotImplementedError()


def update_result_csv(outputs, logger_dir, task_names=None):
    # first, read the content in result_csv file

    performance_result_path = os.path.join(logger_dir, "benchmark_performance.json")

    os.makedirs(os.path.dirname(performance_result_path), exist_ok=True)
    # task average of output
    final_output = dict()
    tasks = [list(o.keys()) for o in outputs]
    tasks = list(set([item for sublist in tasks for item in sublist]))

    for task in tasks:
        final_output[task] = []
        for output in outputs:
            if task in output:
                final_output[task].append(output[task])
        final_output[task] = final_output[task][
            0
        ]  # identical, just replicated 4 dataloader

    with open(performance_result_path, "w") as f:
        json.dump(final_output, f, indent=4)


def flatten_dictconfig(config: DictConfig) -> DictConfig:
    """
    Flatten a nested DictConfig into a single level DictConfig with keys as the path to the original keys.

    Args:
    - config (DictConfig): The nested DictConfig to be flattened.
    - parent_key (str, optional): The base key to use for prefixing the keys. Defaults to ''.
    - separator (str, optional): The separator to use between keys. Defaults to '.'.

    Returns:
    - DictConfig: The flattened configuration.
    """

    # only flatten just first level
    items = []
    for k, v in config.items():
        new_key = k
        if isinstance(v, DictConfig):
            for kk, vv in v.items():
                items.append((f"{kk}", vv))
        else:
            items.append((new_key, v))
    return OmegaConf.create(dict(items))


if __name__ == "__main__":
    main()
