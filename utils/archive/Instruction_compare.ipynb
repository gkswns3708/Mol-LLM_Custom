{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6561933",
   "metadata": {},
   "source": [
    "# Instruction í™•ì¸í•˜ëŠ” ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db592235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” [Comparison Start] Task: bace\n",
      "   path_test_set (Writer): Mol-LLM_Custom/checkpoint/mol-llm_testset\n",
      "   path_my_dataset (Download): Mol-LLM_Custom/dataset/real_train/mistralai-Mistral-7B-Instruct-v0.3_string+graph_q32_test_3.3M_0415_download_InstructGraph_bace\n",
      "\n",
      "â³ Filtering 'bace' task...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter:   0%|          | 0/58757 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58757/58757 [00:32<00:00, 1813.92 examples/s]\n",
      "Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 1981.65 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š [Count Check]\n",
      "   Writer (Testset) 'bace' samples: 152\n",
      "   My (Download)    'bace' samples: 152\n",
      "\n",
      "ğŸ“ [Example Instruction from Writer Dataset]\n",
      "<s>[INST] You are a helpful assistant for molecular chemistry, to address tasks including molecular property classification, molecular property regression, chemical reaction prediction, molecule captioning, molecule generation. \n",
      "\n",
      "Using <INPUT_MOLECULE_PLACEHOLDER> as the molecule, tell me the biological activity against BACE-1. [/INST]\n",
      "\n",
      "âš–ï¸  [Analysis Result]\n",
      "   Unique Instructions in Writer: 13\n",
      "   Unique Instructions in My Data: 13\n",
      "   Common Instructions (Match):    13\n",
      "\n",
      "âœ… SUCCESS: The instruction sets are IDENTICAL!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "from datasets import load_from_disk\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. ê²½ë¡œ ì„¤ì • (ìš”ì²­í•˜ì‹  ëŒ€ë¡œ ë§¤í•‘)\n",
    "# ==============================================================================\n",
    "# Writer (Testset)\n",
    "path_test_set = \"Mol-LLM_Custom/checkpoint/mol-llm_testset\"\n",
    "\n",
    "# Download (My Dataset)\n",
    "path_my_dataset = \"Mol-LLM_Custom/dataset/real_train/mistralai-Mistral-7B-Instruct-v0.3_string+graph_q32_test_3.3M_0415_download_InstructGraph_bace\"\n",
    "\n",
    "def get_clean_instruction(prompt_text):\n",
    "    \"\"\"\n",
    "    prompt_textì—ì„œ <SELFIES> ... </GRAPH> êµ¬ê°„ì„ ì œê±°í•˜ì—¬\n",
    "    ìˆœìˆ˜ Instruction(í…œí”Œë¦¿)ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    if not prompt_text:\n",
    "        return \"\"\n",
    "        \n",
    "    # <SELFIES> ë¡œ ì‹œì‘í•´ì„œ </GRAPH> ë¡œ ëë‚˜ëŠ” íŒ¨í„´ ì œê±° (DOTALL: ì¤„ë°”ê¿ˆ í¬í•¨)\n",
    "    pattern = r\"<SELFIES>.*?</GRAPH>\"\n",
    "    \n",
    "    # í•´ë‹¹ íŒ¨í„´ì„ placeholderë¡œ ì¹˜í™˜\n",
    "    clean_text = re.sub(pattern, \"<INPUT_MOLECULE_PLACEHOLDER>\", prompt_text, flags=re.DOTALL)\n",
    "    \n",
    "    return clean_text.strip()\n",
    "\n",
    "def compare_bace_instructions(dataset_path_writer, dataset_path_my, task_name=\"bace\"):\n",
    "    print(f\"ğŸ” [Comparison Start] Task: {task_name}\")\n",
    "    print(f\"   path_test_set (Writer): {dataset_path_writer}\")\n",
    "    print(f\"   path_my_dataset (Download): {dataset_path_my}\\n\")\n",
    "\n",
    "    # 1. ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "    try:\n",
    "        ds_writer = load_from_disk(dataset_path_writer)\n",
    "        ds_my = load_from_disk(dataset_path_my)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading datasets: {e}\")\n",
    "        return\n",
    "\n",
    "    # 2. BACE íƒœìŠ¤í¬ í•„í„°ë§ í•¨ìˆ˜ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ ë° ì—¬ëŸ¬ ì»¬ëŸ¼ í™•ì¸)\n",
    "    def filter_func(x):\n",
    "        # 1. 'task'ë‚˜ 'dataset' ì»¬ëŸ¼ í™•ì¸\n",
    "        for col in ['task', 'task_subtask_pair', 'dataset']:\n",
    "            if x.get(col) and task_name in str(x[col]).lower():\n",
    "                return True\n",
    "        # 2. ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ë‚´ìš© í™•ì¸ (fallback)\n",
    "        text_content = x.get('prompt_text') or x.get('text') or x.get('instruction') or \"\"\n",
    "        if task_name in str(text_content).lower():\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    print(\"â³ Filtering 'bace' task...\")\n",
    "    ds_writer_bace = ds_writer.filter(filter_func)\n",
    "    ds_my_bace = ds_my.filter(filter_func)\n",
    "\n",
    "    print(f\"ğŸ“Š [Count Check]\")\n",
    "    print(f\"   Writer (Testset) '{task_name}' samples: {len(ds_writer_bace)}\")\n",
    "    print(f\"   My (Download)    '{task_name}' samples: {len(ds_my_bace)}\")\n",
    "\n",
    "    if len(ds_writer_bace) == 0 or len(ds_my_bace) == 0:\n",
    "        print(\"âš ï¸ Warning: One of the datasets has 0 samples for this task. Check filter logic.\")\n",
    "        return\n",
    "\n",
    "    # 3. Instruction ì¶”ì¶œ ë° ì§‘í•©(Set) ìƒì„±\n",
    "    instructions_writer = set()\n",
    "    instructions_my = set()\n",
    "\n",
    "    # í…ìŠ¤íŠ¸ê°€ ë“¤ì–´ìˆëŠ” ì»¬ëŸ¼ëª… ì°¾ê¸° í•¨ìˆ˜\n",
    "    def get_text_column(ds):\n",
    "        for candidate in ['prompt_text', 'text', 'instruction', 'input']:\n",
    "            if candidate in ds.column_names:\n",
    "                return candidate\n",
    "        return None\n",
    "\n",
    "    col_writer = get_text_column(ds_writer_bace)\n",
    "    col_my = get_text_column(ds_my_bace)\n",
    "\n",
    "    if not col_writer or not col_my:\n",
    "        print(f\"âŒ Could not find text column. Available keys: {ds_writer_bace.column_names} / {ds_my_bace.column_names}\")\n",
    "        return\n",
    "\n",
    "    # Writer ë°ì´í„°ì…‹ ì¶”ì¶œ\n",
    "    for i, item in enumerate(ds_writer_bace):\n",
    "        clean_inst = get_clean_instruction(item[col_writer])\n",
    "        instructions_writer.add(clean_inst)\n",
    "        if i == 0:\n",
    "            print(f\"\\nğŸ“ [Example Instruction from Writer Dataset]\")\n",
    "            print(f\"{clean_inst}\")\n",
    "\n",
    "    # My ë°ì´í„°ì…‹ ì¶”ì¶œ\n",
    "    for item in ds_my_bace:\n",
    "        clean_inst = get_clean_instruction(item[col_my])\n",
    "        instructions_my.add(clean_inst)\n",
    "\n",
    "    # 4. ë¹„êµ ë¶„ì„\n",
    "    common_inst = instructions_writer.intersection(instructions_my)\n",
    "    only_in_writer = instructions_writer - instructions_my\n",
    "    only_in_my = instructions_my - instructions_writer\n",
    "\n",
    "    print(f\"\\nâš–ï¸  [Analysis Result]\")\n",
    "    print(f\"   Unique Instructions in Writer: {len(instructions_writer)}\")\n",
    "    print(f\"   Unique Instructions in My Data: {len(instructions_my)}\")\n",
    "    print(f\"   Common Instructions (Match):    {len(common_inst)}\")\n",
    "\n",
    "    if len(only_in_writer) == 0 and len(only_in_my) == 0:\n",
    "        print(\"\\nâœ… SUCCESS: The instruction sets are IDENTICAL!\")\n",
    "    else:\n",
    "        print(\"\\nâŒ DIFFERENCE DETECTED!\")\n",
    "        \n",
    "        if len(only_in_writer) > 0:\n",
    "            print(f\"\\n[!] Instructions ONLY in Writer Dataset ({len(only_in_writer)}):\")\n",
    "            for idx, inst in enumerate(list(only_in_writer)[:3]):\n",
    "                print(f\"   {idx+1}. {inst[:100]}...\")\n",
    "\n",
    "        if len(only_in_my) > 0:\n",
    "            print(f\"\\n[!] Instructions ONLY in My Dataset ({len(only_in_my)}):\")\n",
    "            for idx, inst in enumerate(list(only_in_my)[:3]):\n",
    "                print(f\"   {idx+1}. {inst[:100]}...\")\n",
    "\n",
    "# ==============================================================================\n",
    "# ì‹¤í–‰\n",
    "# ==============================================================================\n",
    "compare_bace_instructions(path_test_set, path_my_dataset, task_name=\"bace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bfb063",
   "metadata": {},
   "source": [
    "# Moelcular ì¢…ë¥˜ì™€ graph feature í™•ì¸í•˜ëŠ” ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a11265f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Loading Dataset 1 (Reference): Mol-LLM_Custom/dataset/real_train/mistralai-Mistral-7B-Instruct-v0.3_string+graph_q32_test_3.3M_0415_download_InstructGraph_bace\n",
      "ğŸ“‚ Loading Dataset 2 (Target): Mol-LLM_Custom/checkpoint/mol-llm_testset\n",
      "   Original Dataset 2 size: 58757\n",
      "ğŸ” Filtering 'bace' from Dataset 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter:   0%|          | 0/58757 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58757/58757 [00:32<00:00, 1821.40 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Filtered Dataset 2 size: 152 (Only 'bace')\n",
      "âœ… Sizes match: 152 samples. Starting deep comparison...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Comparing Samples: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 890.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‰ SUCCESS: All Filtered BACE samples (Strings & Graphs) are IDENTICAL!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_from_disk\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# ==========================================\n",
    "# 1. ì„¤ì •: ê²½ë¡œ ì…ë ¥\n",
    "# ==========================================\n",
    "dataset_download_InstructGraph = \"Mol-LLM_Custom/dataset/real_train/mistralai-Mistral-7B-Instruct-v0.3_string+graph_q32_test_3.3M_0415_download_InstructGraph_bace\"\n",
    "dataset_writer = \"Mol-LLM_Custom/checkpoint/mol-llm_testset\"\n",
    "\n",
    "def deep_compare_datasets(path1, path2):\n",
    "    print(f\"ğŸ“‚ Loading Dataset 1 (Reference): {path1}\")\n",
    "    ds1 = load_from_disk(path1)\n",
    "    \n",
    "    print(f\"ğŸ“‚ Loading Dataset 2 (Target): {path2}\")\n",
    "    ds2_raw = load_from_disk(path2)\n",
    "    print(f\"   Original Dataset 2 size: {len(ds2_raw)}\")\n",
    "\n",
    "    # ==========================================\n",
    "    # 2. Dataset 2ì—ì„œ 'bace' í•„í„°ë§ ìˆ˜í–‰\n",
    "    # ==========================================\n",
    "    print(\"ğŸ” Filtering 'bace' from Dataset 2...\")\n",
    "    \n",
    "    # í•„í„°ë§ í•¨ìˆ˜ ì •ì˜\n",
    "    def filter_bace(example):\n",
    "        # 1ìˆœìœ„: 'task'ë‚˜ 'dataset' ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ í™•ì¸\n",
    "        if 'task' in example and example['task'] is not None:\n",
    "            if 'bace' in str(example['task']).lower():\n",
    "                return True\n",
    "        if 'dataset' in example and example['dataset'] is not None:\n",
    "            if 'bace' in str(example['dataset']).lower():\n",
    "                return True\n",
    "        \n",
    "        # 2ìˆœìœ„: ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ Instruction(ì§€ì‹œë¬¸) í…ìŠ¤íŠ¸ ì•ˆì— 'bace'ê°€ ìˆëŠ”ì§€ í™•ì¸\n",
    "        if 'instruction' in example:\n",
    "            if 'bace' in example['instruction'].lower():\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "    # í•„í„° ì ìš©\n",
    "    ds2 = ds2_raw.filter(filter_bace)\n",
    "    print(f\"   Filtered Dataset 2 size: {len(ds2)} (Only 'bace')\")\n",
    "\n",
    "    # ==========================================\n",
    "    # 3. ë°ì´í„° ê°œìˆ˜ ë° ì •ë ¬ í™•ì¸\n",
    "    # ==========================================\n",
    "    if len(ds1) != len(ds2):\n",
    "        print(f\"âŒ SIZE MISMATCH: Dataset 1 has {len(ds1)}, but Filtered Dataset 2 has {len(ds2)}.\")\n",
    "        print(\"   -> ê°œìˆ˜ê°€ ë‹¤ë¥´ë©´ 1:1 ë¹„êµê°€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. í•„í„°ë§ ì¡°ê±´ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "        return\n",
    "\n",
    "    print(f\"âœ… Sizes match: {len(ds1)} samples. Starting deep comparison...\")\n",
    "\n",
    "    mismatch_count = 0\n",
    "    keys_to_check = ['selfies', 'graph', 'input_ids', 'labels'] \n",
    "    \n",
    "    # tqdmìœ¼ë¡œ ì§„í–‰ ìƒí™© í‘œì‹œ\n",
    "    for idx in tqdm(range(len(ds1)), desc=\"Comparing Samples\"):\n",
    "        sample1 = ds1[idx]\n",
    "        sample2 = ds2[idx]\n",
    "\n",
    "        diff_found = False\n",
    "        log_msg = []\n",
    "\n",
    "        # === 4. SELFIES (ë¬¸ìì—´) ë¹„êµ ===\n",
    "        # í‚¤ ì´ë¦„ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‹ˆ í™•ì¸ (selfies, input, text ë“±)\n",
    "        key_s1 = 'selfies' if 'selfies' in sample1 else 'input'\n",
    "        key_s2 = 'selfies' if 'selfies' in sample2 else 'input'\n",
    "        \n",
    "        # ì–‘ìª½ì— í•´ë‹¹ í‚¤ê°€ ìˆì„ ë•Œë§Œ ë¹„êµ\n",
    "        if key_s1 in sample1 and key_s2 in sample2:\n",
    "            val1 = sample1[key_s1]\n",
    "            val2 = sample2[key_s2]\n",
    "            if val1 != val2:\n",
    "                diff_found = True\n",
    "                log_msg.append(f\"String mismatch: ds1['{key_s1}'] != ds2['{key_s2}']\")\n",
    "                # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ ìˆ˜ ìˆìœ¼ë‹ˆ ì•ë¶€ë¶„ë§Œ ì¶œë ¥\n",
    "                log_msg.append(f\"   -> 1: {str(val1)[:30]}...\")\n",
    "                log_msg.append(f\"   -> 2: {str(val2)[:30]}...\")\n",
    "\n",
    "        # === 5. Graph Data (í…ì„œ/ë°°ì—´) ë¹„êµ ===\n",
    "        if 'graph' in sample1 and 'graph' in sample2:\n",
    "            g1 = sample1['graph']\n",
    "            g2 = sample2['graph']\n",
    "            \n",
    "            # (1) Node Features (x)\n",
    "            k1 = 'x' if 'x' in g1 else 'node_feat'\n",
    "            k2 = 'x' if 'x' in g2 else 'node_feat'\n",
    "            \n",
    "            if k1 in g1 and k2 in g2:\n",
    "                arr1 = np.array(g1[k1])\n",
    "                arr2 = np.array(g2[k2])\n",
    "                if arr1.shape != arr2.shape:\n",
    "                    diff_found = True\n",
    "                    log_msg.append(f\"Graph Node Feature Shape mismatch: {arr1.shape} vs {arr2.shape}\")\n",
    "                elif not np.allclose(arr1, arr2, atol=1e-5): # ì†Œìˆ˜ì  ì˜¤ì°¨ í—ˆìš©\n",
    "                    diff_found = True\n",
    "                    log_msg.append(f\"Graph Node Feature ({k1}) values mismatch\")\n",
    "\n",
    "            # (2) Edge Index\n",
    "            if 'edge_index' in g1 and 'edge_index' in g2:\n",
    "                arr1 = np.array(g1['edge_index'])\n",
    "                arr2 = np.array(g2['edge_index'])\n",
    "                if arr1.shape != arr2.shape:\n",
    "                    diff_found = True\n",
    "                    log_msg.append(f\"Edge Index Shape mismatch: {arr1.shape} vs {arr2.shape}\")\n",
    "                elif not np.array_equal(arr1, arr2): # ì •ìˆ˜ëŠ” ì™„ì „ ì¼ì¹˜\n",
    "                    diff_found = True\n",
    "                    log_msg.append(\"Graph Edge Index mismatch (Different connections)\")\n",
    "\n",
    "            # (3) Edge Attributes\n",
    "            if 'edge_attr' in g1 and 'edge_attr' in g2:\n",
    "                arr1 = np.array(g1['edge_attr'])\n",
    "                arr2 = np.array(g2['edge_attr'])\n",
    "                if not np.allclose(arr1, arr2, atol=1e-5):\n",
    "                    diff_found = True\n",
    "                    log_msg.append(\"Graph Edge Attributes mismatch\")\n",
    "\n",
    "        # ê²°ê³¼ ì¶œë ¥\n",
    "        if diff_found:\n",
    "            mismatch_count += 1\n",
    "            print(f\"\\nâš ï¸ Mismatch found at Index {idx}:\")\n",
    "            for msg in log_msg:\n",
    "                print(f\"   - {msg}\")\n",
    "            \n",
    "            if mismatch_count > 5:\n",
    "                print(\"\\nâ›” Too many mismatches found. Stopping early.\")\n",
    "                break\n",
    "\n",
    "    if mismatch_count == 0:\n",
    "        print(\"\\nğŸ‰ SUCCESS: All Filtered BACE samples (Strings & Graphs) are IDENTICAL!\")\n",
    "    else:\n",
    "        print(f\"\\nâŒ FOUND {mismatch_count} mismatches.\")\n",
    "\n",
    "# ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    deep_compare_datasets(dataset_download_InstructGraph, dataset_writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bf4c0a",
   "metadata": {},
   "source": [
    "# download datasetì„ writerì˜ instruction setìœ¼ë¡œ ë³€ê²½í•˜ëŠ” ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d613abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Loading Reference Dataset (Test Set)...\n",
      "ğŸ§© Extracting Template from Reference...\n",
      "   âœ… Template Extracted successfully!\n",
      "      Prefix end: ...' molecule generation. \\n\\nUsing '\n",
      "      Suffix start: ' as the molecule, tell me the '...\n",
      "\n",
      "ğŸ“‚ Loading Target Dataset (To be fixed)...\n",
      "   Target size: 152\n",
      "\n",
      "ğŸ”„ Applying Reference Template to Target Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing Instructions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 5322.77 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Checking Result (First Sample):\n",
      "<s>[INST] You are a helpful assistant for molecular chemistry, to address tasks including molecular property classification, molecular property regression, chemical reaction prediction, molecule capti ... \n",
      "\n",
      "ğŸ’¾ Saving fixed dataset to: Mol-LLM_Custom/dataset/real_train/mistralai-Mistral-7B-Instruct-v0.3_string+graph_q32_test_3.3M_0415_download_InstructGraph_bace_FIXED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 15286.39 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done! ì´ì œ ì´ ë°ì´í„°ì…‹ì€ Test Setê³¼ ì™„ë²½íˆ ë™ì¼í•œ Instruction í˜•ì‹ì„ ê°€ì§‘ë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datasets import load_from_disk\n",
    "import os\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. ê²½ë¡œ ì„¤ì •\n",
    "# ==============================================================================\n",
    "# [Reference] ì˜¬ë°”ë¥¸ í˜•ì‹ì„ ê°€ì§„ Test Set ê²½ë¡œ\n",
    "path_reference = \"Mol-LLM_Custom/checkpoint/mol-llm_testset\"\n",
    "\n",
    "# [Target] ìˆ˜ì •í•˜ê³  ì‹¶ì€ ë‚´ ë°ì´í„°ì…‹ ê²½ë¡œ (Download)\n",
    "path_target_original = \"Mol-LLM_Custom/dataset/real_train/mistralai-Mistral-7B-Instruct-v0.3_string+graph_q32_test_3.3M_0415_download_InstructGraph_bace\"\n",
    "\n",
    "# [Output] ìˆ˜ì • í›„ ì €ì¥í•  ìƒˆë¡œìš´ ê²½ë¡œ\n",
    "path_output_fixed = \"Mol-LLM_Custom/dataset/real_train/mistralai-Mistral-7B-Instruct-v0.3_string+graph_q32_test_3.3M_0415_download_InstructGraph_bace_FIXED\"\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. í•¨ìˆ˜ ì •ì˜\n",
    "# ==============================================================================\n",
    "\n",
    "def extract_template_parts(prompt_text):\n",
    "    \"\"\"\n",
    "    Test Setì˜ ìƒ˜í”Œ í…ìŠ¤íŠ¸ì—ì„œ ë¶„ì ì •ë³´(<SELFIES>...<GRAPH>...)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ\n",
    "    'ì•ë¶€ë¶„(Prefix)'ê³¼ 'ë’·ë¶€ë¶„(Suffix)'ì„ ë¶„ë¦¬í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # ì •ê·œí‘œí˜„ì‹: <SELFIES>ë¡œ ì‹œì‘í•´ì„œ </GRAPH>ë¡œ ëë‚˜ëŠ” êµ¬ê°„ì„ ì°¾ìŒ (ì¤„ë°”ê¿ˆ í¬í•¨)\n",
    "    pattern = r\"(.*)(<SELFIES>.*?</GRAPH>)(.*)\"\n",
    "    match = re.search(pattern, prompt_text, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        prefix = match.group(1) # ì§€ì‹œë¬¸ ì•ë¶€ë¶„ (<s>[INST] ...)\n",
    "        # middle = match.group(2) # ë¶„ì ì •ë³´ (ì´ê±´ ë°ì´í„°ë§ˆë‹¤ ë‹¤ë¥´ë¯€ë¡œ ë²„ë¦¼)\n",
    "        suffix = match.group(3) # ì§€ì‹œë¬¸ ë’·ë¶€ë¶„ ( [/INST] ë“±)\n",
    "        return prefix, suffix\n",
    "    else:\n",
    "        raise ValueError(\"âŒ í…ìŠ¤íŠ¸ì—ì„œ <SELFIES>...<GRAPH> êµ¬ì¡°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í¬ë§·ì´ ë‹¤ë¦…ë‹ˆë‹¤.\")\n",
    "\n",
    "def extract_molecule_part(prompt_text):\n",
    "    \"\"\"\n",
    "    Target ë°ì´í„°ì…‹ì˜ í…ìŠ¤íŠ¸ì—ì„œ 'ë¶„ì ì •ë³´'ë§Œ ì™ ë½‘ì•„ëƒ…ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    pattern = r\"(<SELFIES>.*?</GRAPH>)\"\n",
    "    match = re.search(pattern, prompt_text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        # ë§Œì•½ í…ìŠ¤íŠ¸ì— íƒœê·¸ê°€ ì—†ë‹¤ë©´, ì§ì ‘ êµ¬ì„±í•´ì•¼ í•  ìˆ˜ë„ ìˆìŒ (ì—¬ê¸°ì„œëŠ” ì—ëŸ¬ ì²˜ë¦¬)\n",
    "        return None\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. ë©”ì¸ ë¡œì§\n",
    "# ==============================================================================\n",
    "\n",
    "def standardize_dataset():\n",
    "    print(\"ğŸ“‚ Loading Reference Dataset (Test Set)...\")\n",
    "    ds_ref = load_from_disk(path_reference)\n",
    "    \n",
    "    # BACE íƒœìŠ¤í¬ ìƒ˜í”Œ í•˜ë‚˜ë§Œ ì°¾ì•„ì„œ í…œí”Œë¦¿ ì¶”ì¶œ\n",
    "    # (íš¨ìœ¨ì„ ìœ„í•´ ì „ì²´ë¥¼ ëŒì§€ ì•Šê³ , baceê°€ í¬í•¨ëœ ì²« ë²ˆì§¸ ìƒ˜í”Œì„ ì°¾ìŒ)\n",
    "    ref_sample = None\n",
    "    for item in ds_ref:\n",
    "        t = item.get('prompt_text', '')\n",
    "        if 'bace' in t.lower() and '<SELFIES>' in t:\n",
    "            ref_sample = item\n",
    "            break\n",
    "            \n",
    "    if ref_sample is None:\n",
    "        print(\"âŒ Reference Datasetì—ì„œ BACE ê´€ë ¨ ìƒ˜í”Œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    print(\"ğŸ§© Extracting Template from Reference...\")\n",
    "    try:\n",
    "        prefix_template, suffix_template = extract_template_parts(ref_sample['prompt_text'])\n",
    "        print(f\"   âœ… Template Extracted successfully!\")\n",
    "        print(f\"      Prefix end: ...{prefix_template[-30:]!r}\")\n",
    "        print(f\"      Suffix start: {suffix_template[:30]!r}...\")\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        return\n",
    "\n",
    "    print(\"\\nğŸ“‚ Loading Target Dataset (To be fixed)...\")\n",
    "    ds_target = load_from_disk(path_target_original)\n",
    "    \n",
    "    # Target ë°ì´í„°ì…‹ì—ì„œ BACEë§Œ í•„í„°ë§ (í•„ìš”ì‹œ)\n",
    "    # ds_target = ds_target.filter(lambda x: 'bace' in str(x.get('task', '')).lower())\n",
    "\n",
    "    print(f\"   Target size: {len(ds_target)}\")\n",
    "\n",
    "    # ============================================================\n",
    "    # 4. ë°ì´í„°ì…‹ ë³€í™˜ (Map í•¨ìˆ˜ ì ìš©)\n",
    "    # ============================================================\n",
    "    def apply_template(example):\n",
    "        # 1. í˜„ì¬ ìƒ˜í”Œì˜ ì›ë³¸ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
    "        original_text = example.get('prompt_text') or example.get('text')\n",
    "        \n",
    "        # 2. ë‚´ ë°ì´í„°ì˜ 'ë¶„ì ì •ë³´' (<SELFIES>...<GRAPH>...) ì¶”ì¶œ\n",
    "        molecule_part = extract_molecule_part(original_text)\n",
    "        \n",
    "        # ë§Œì•½ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œì´ ì•ˆ ë˜ë©´, input_idsë‚˜ graph í•„ë“œì—ì„œ ì¬êµ¬ì„±í•´ì•¼ í•¨\n",
    "        # ì—¬ê¸°ì„œëŠ” í…ìŠ¤íŠ¸ê°€ ì¡´ì¬í•œë‹¤ê³  ê°€ì •\n",
    "        if molecule_part is None:\n",
    "            # ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ì›ë³¸ ë°˜í™˜ (í˜¹ì€ ë¡œê¹…)\n",
    "            return example \n",
    "        \n",
    "        # 3. Reference í…œí”Œë¦¿ + ë‚´ ë¶„ì ì •ë³´ ê²°í•©\n",
    "        new_text = prefix_template + molecule_part + suffix_template\n",
    "        \n",
    "        # 4. ì»¬ëŸ¼ ì—…ë°ì´íŠ¸\n",
    "        example['prompt_text'] = new_text\n",
    "        \n",
    "        # ì£¼ì˜: input_idsê°€ ë¯¸ë¦¬ í† í°í™”ë˜ì–´ ì €ì¥ëœ ê²½ìš°, í…ìŠ¤íŠ¸ê°€ ë°”ë€Œì—ˆìœ¼ë¯€ë¡œ\n",
    "        # input_idsëŠ” ë¬´íš¨í™”ë˜ê±°ë‚˜ ë‹¤ì‹œ í† í¬ë‚˜ì´ì§• í•´ì•¼ í•¨.\n",
    "        # ì—¬ê¸°ì„œëŠ” í…ìŠ¤íŠ¸ë§Œ ë§ì¶”ëŠ” ê²ƒì´ë¯€ë¡œ input_idsëŠ” ê·¸ëŒ€ë¡œ ë‘ê±°ë‚˜ ì‚­ì œí•  ìˆ˜ ìˆìŒ.\n",
    "        # example['input_ids'] = ... (í† í¬ë‚˜ì´ì €ê°€ ìˆë‹¤ë©´ ì—¬ê¸°ì„œ ìˆ˜í–‰)\n",
    "        \n",
    "        return example\n",
    "\n",
    "    print(\"\\nğŸ”„ Applying Reference Template to Target Dataset...\")\n",
    "    ds_fixed = ds_target.map(apply_template, desc=\"Standardizing Instructions\")\n",
    "\n",
    "    # ============================================================\n",
    "    # 5. ê²°ê³¼ í™•ì¸ ë° ì €ì¥\n",
    "    # ============================================================\n",
    "    print(\"\\nğŸ“ Checking Result (First Sample):\")\n",
    "    print(ds_fixed[0]['prompt_text'][:200] + \" ... \")\n",
    "\n",
    "    print(f\"\\nğŸ’¾ Saving fixed dataset to: {path_output_fixed}\")\n",
    "    ds_fixed.save_to_disk(path_output_fixed)\n",
    "    print(\"âœ… Done! ì´ì œ ì´ ë°ì´í„°ì…‹ì€ Test Setê³¼ ì™„ë²½íˆ ë™ì¼í•œ Instruction í˜•ì‹ì„ ê°€ì§‘ë‹ˆë‹¤.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    standardize_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f51333",
   "metadata": {},
   "source": [
    "# Writerì˜ Datasetì„ ì „ì²´ Instruction Set ë‚´ì—ì„œ Random Instructionìœ¼ë¡œ ìˆ˜ì •."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f286ed47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Loading Reference Dataset: Mol-LLM_Custom/checkpoint/mol-llm_testset\n",
      "ğŸ” Filtering Reference for 'bace' task...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter:   0%|          | 0/58757 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58757/58757 [00:33<00:00, 1773.71 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Original Size: 58757 -> BACE Only Size: 152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting Templates: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 1717.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Collected 13 unique BACE instruction templates.\n",
      "\n",
      "ğŸ“‚ Loading Target Dataset: Mol-LLM_Custom/dataset/real_train/mistralai-Mistral-7B-Instruct-v0.3_string+graph_q32_test_3.3M_0415_download_bace\n",
      "   Target Size: 152\n",
      "\n",
      "ğŸ”€ Swapping instructions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 4959.19 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Result Preview (First Sample):\n",
      "--------------------------------------------------\n",
      "<s>[INST] You are a helpful assistant for molecular chemistry, to address tasks including molecular property classification, molecular property regression, chemical reaction prediction, molecule captioning, molecule generation. \n",
      "\n",
      "<SELFIES> [C][C][=C][C][=C][C][=C][Ring1][=Branch1][C][=C][C][=C][N][= ... \n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ’¾ Saving to: Mol-LLM_Custom/dataset/real_train/mistralai-Mistral-7B-Instruct-v0.3_string+graph_q32_test_3.3M_0415_download_bace_SWAPPED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 14841.22 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed Successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "import os\n",
    "from datasets import load_from_disk\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. ê²½ë¡œ ì„¤ì •\n",
    "# ==============================================================================\n",
    "\n",
    "# [Reference] Writerì˜ ì „ì²´ ë°ì´í„°ì…‹ (ì—¬ê¸°ì„œ BACE Instructionë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤)\n",
    "path_reference = \"Mol-LLM_Custom/checkpoint/mol-llm_testset\"\n",
    "\n",
    "# [Target] ë‚´ BACE ì „ìš© ë°ì´í„°ì…‹ (ìˆ˜ì • ëŒ€ìƒ)\n",
    "path_target = \"Mol-LLM_Custom/dataset/real_train/mistralai-Mistral-7B-Instruct-v0.3_string+graph_q32_test_3.3M_0415_download_bace\"\n",
    "\n",
    "# [Output] ê²°ê³¼ ì €ì¥ ê²½ë¡œ\n",
    "path_output = \"Mol-LLM_Custom/dataset/real_train/mistralai-Mistral-7B-Instruct-v0.3_string+graph_q32_test_3.3M_0415_download_bace_SWAPPED\"\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. í—¬í¼ í•¨ìˆ˜ ì •ì˜\n",
    "# ==============================================================================\n",
    "\n",
    "def extract_parts(text):\n",
    "    \"\"\"\n",
    "    í…ìŠ¤íŠ¸ë¥¼ [Instruction ì•ë¶€ë¶„] + [ë¶„ì ì •ë³´] + [Instruction ë’·ë¶€ë¶„]ìœ¼ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.\n",
    "    ë¶„ì ì •ë³´ëŠ” <SELFIES> íƒœê·¸ë¡œ ì‹œì‘í•´ì„œ </GRAPH> íƒœê·¸ë¡œ ëë‚œë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    pattern = r\"(.*)(<SELFIES>.*?</GRAPH>)(.*)\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        prefix = match.group(1)\n",
    "        molecule = match.group(2)\n",
    "        suffix = match.group(3)\n",
    "        return prefix, molecule, suffix\n",
    "    return None, None, None\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. ë©”ì¸ ë¡œì§\n",
    "# ==============================================================================\n",
    "\n",
    "def main():\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Step 1. Reference ë°ì´í„°ì…‹ì—ì„œ BACE Instruction ìˆ˜ì§‘ (Template Pool ìƒì„±)\n",
    "    # --------------------------------------------------------------------------\n",
    "    print(f\"ğŸ“‚ Loading Reference Dataset: {path_reference}\")\n",
    "    ds_ref = load_from_disk(path_reference)\n",
    "    \n",
    "    print(\"ğŸ” Filtering Reference for 'bace' task...\")\n",
    "    # task ì»¬ëŸ¼ì´ 'bace'ë¥¼ í¬í•¨í•˜ê±°ë‚˜, í…ìŠ¤íŠ¸ ë‚´ì— 'bace' ê´€ë ¨ ë‚´ìš©ì´ ìˆëŠ”ì§€ í™•ì¸ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)\n",
    "    ds_ref_bace = ds_ref.filter(\n",
    "        lambda x: 'bace' in str(x.get('task', '')).lower()\n",
    "    )\n",
    "    \n",
    "    print(f\"   Original Size: {len(ds_ref)} -> BACE Only Size: {len(ds_ref_bace)}\")\n",
    "    \n",
    "    if len(ds_ref_bace) == 0:\n",
    "        print(\"âŒ Error: Reference ë°ì´í„°ì…‹ì—ì„œ 'bace' íƒœìŠ¤í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    # í…œí”Œë¦¿(ì§ˆë¬¸ íŒ¨í„´) ìˆ˜ì§‘\n",
    "    template_pool = set()\n",
    "    for item in tqdm(ds_ref_bace, desc=\"Collecting Templates\"):\n",
    "        text = item.get('prompt_text') or item.get('text', '')\n",
    "        if '<SELFIES>' not in text: \n",
    "            continue\n",
    "            \n",
    "        prefix, _, suffix = extract_parts(text)\n",
    "        if prefix is not None:\n",
    "            template_pool.add((prefix, suffix))\n",
    "    \n",
    "    template_pool = list(template_pool)\n",
    "    print(f\"âœ… Collected {len(template_pool)} unique BACE instruction templates.\")\n",
    "    \n",
    "    if len(template_pool) < 2:\n",
    "        print(\"âš ï¸ Warning: ìˆ˜ì§‘ëœ í…œí”Œë¦¿ì´ 1ê°œ ì´í•˜ì…ë‹ˆë‹¤. êµì²´ íš¨ê³¼ê°€ ê±°ì˜ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Step 2. Target ë°ì´í„°ì…‹ ë¡œë“œ ë° Instruction êµì²´\n",
    "    # --------------------------------------------------------------------------\n",
    "    print(f\"\\nğŸ“‚ Loading Target Dataset: {path_target}\")\n",
    "    ds_target = load_from_disk(path_target)\n",
    "    print(f\"   Target Size: {len(ds_target)}\")\n",
    "\n",
    "    def swap_instruction_fn(example):\n",
    "        original_text = example.get('prompt_text') or example.get('text')\n",
    "        \n",
    "        # 1. ë¶„ì ì •ë³´ ì¶”ì¶œ\n",
    "        curr_prefix, molecule_part, curr_suffix = extract_parts(original_text)\n",
    "        \n",
    "        # ë¶„ì ì •ë³´ê°€ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜\n",
    "        if molecule_part is None:\n",
    "            return example\n",
    "        \n",
    "        # 2. í…œí”Œë¦¿ ì„ íƒ (í˜„ì¬ ê²ƒê³¼ ë‹¤ë¥¸ ê²ƒì„ ìš°ì„  ì„ íƒ)\n",
    "        candidates = [t for t in template_pool if t != (curr_prefix, curr_suffix)]\n",
    "        \n",
    "        # ë§Œì•½ í›„ë³´ê°€ ì—†ìœ¼ë©´(ì „ë¶€ ë˜‘ê°™ê±°ë‚˜ í’€ì´ ì‘ìœ¼ë©´) ì „ì²´ í’€ì—ì„œ ì„ íƒ\n",
    "        if not candidates:\n",
    "            candidates = template_pool\n",
    "            \n",
    "        new_prefix, new_suffix = random.choice(candidates)\n",
    "        \n",
    "        # 3. ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ ì¡°ë¦½\n",
    "        new_text = new_prefix + molecule_part + new_suffix\n",
    "        example['prompt_text'] = new_text\n",
    "        \n",
    "        # 4. [ì¤‘ìš”] í…ìŠ¤íŠ¸ê°€ ë°”ë€Œì—ˆìœ¼ë¯€ë¡œ ê¸°ì¡´ í† í° ID(input_ids) ì‚­ì œ\n",
    "        #    ì´ë ‡ê²Œ í•´ì•¼ ë‚˜ì¤‘ì— Dataset ë¡œë“œ ì‹œ í…ìŠ¤íŠ¸ë§Œ ë³´ê³  ìƒˆë¡œ í† í¬ë‚˜ì´ì§•ì„ í•˜ê±°ë‚˜\n",
    "        #    ìµœì†Œí•œ ì˜ˆì „ í† í°ì„ ì“°ëŠ” ì‹¤ìˆ˜ë¥¼ ë§‰ì„ ìˆ˜ ìˆìŒ.\n",
    "        if 'input_ids' in example:\n",
    "            example['input_ids'] = []  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™” ë˜ëŠ” del example['input_ids']\n",
    "        if 'attention_mask' in example:\n",
    "            example['attention_mask'] = []\n",
    "\n",
    "        return example\n",
    "\n",
    "    print(\"\\nğŸ”€ Swapping instructions...\")\n",
    "    ds_swapped = ds_target.map(swap_instruction_fn, desc=\"Processing\")\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Step 3. ê²°ê³¼ í™•ì¸ ë° ì €ì¥\n",
    "    # --------------------------------------------------------------------------\n",
    "    print(\"\\nğŸ“ Result Preview (First Sample):\")\n",
    "    print(\"-\" * 50)\n",
    "    print(ds_swapped[0]['prompt_text'][:300] + \" ... \")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    print(f\"\\nğŸ’¾ Saving to: {path_output}\")\n",
    "    ds_swapped.save_to_disk(path_output)\n",
    "    print(\"âœ… Completed Successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b74a50",
   "metadata": {},
   "source": [
    "# molecule ë¼ë¦¬ì˜ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9b5517a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Loading Datasets...\n",
      "   Ref Size: 58757\n",
      "   Target Size: 152\n",
      "\n",
      "ğŸ” Indexing Reference Dataset by 'prompt_text'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Index: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 1504.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Indexed 152 unique prompts from Reference.\n",
      "\n",
      "âš–ï¸  Starting Comparison (Matching logic: prompt_text)...\n",
      "\n",
      "====================================================================================================\n",
      "ğŸ”¥ MATCH FOUND #1 (Dataset Index: 17)\n",
      "   Prompt Text: <s>[INST] You are a helpful assistant for molecular chemistry, to address tasks including molecular  ... (Identical)\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ”¹ [Input Mol Strings]\n",
      "   Target: <SELFIES> [C][C][N][C][=C][C][=C][Branch2][Ring2][=N][C][=C][Branch2][Ring1][S][C][=Branch1][C][=O][N][C][Branch1][#Branch2][C][C][=C][C][=C][C][=C][Ring1][=Branch1][C@H1][Branch1][C][O][C][N][C][=C][C][=C][C][=C][Ring1][=Branch1][C][=C][Ring2][Ring1][O][Ring2][Ring1][=C][N][Branch1][C][C][S][=Branch1][C][=O][=Branch1][C][=O][C][C][Ring2][Ring2][Ring1] </SELFIES>\n",
      "   Writer: <SELFIES> [C][C][N][C][=C][C][=C][Branch2][Ring2][=N][C][=C][Branch2][Ring1][S][C][=Branch1][C][=O][N][C][Branch1][#Branch2][C][C][=C][C][=C][C][=C][Ring1][=Branch1][C@H1][Branch1][C][O][C][N][C][=C][C][=C][C][=C][Ring1][=Branch1][C][=C][Ring2][Ring1][O][Ring2][Ring1][=C][N][Branch1][C][C][S][=Branch1][C][=O][=Branch1][C][=O][C][C][Ring2][Ring2][Ring1] </SELFIES>\n",
      "   >> âœ… MATCH\n",
      "\n",
      "ğŸ”¹ [Target Text (Label)]\n",
      "   Target: <BOOLEAN> True </BOOLEAN> </s>\n",
      "   Writer: <BOOLEAN> True </BOOLEAN> </s>\n",
      "   >> âœ… MATCH\n",
      "\n",
      "ğŸ”¹ [Graph Node Feat (x)]\n",
      "   Target: None\n",
      "   Writer: None\n",
      "   >> âœ… MATCH\n",
      "\n",
      "ğŸ”¹ [Graph Edge Index]\n",
      "   Target: None\n",
      "   Writer: None\n",
      "   >> âœ… MATCH\n",
      "\n",
      "ğŸ”¹ [Graph Edge Attr]\n",
      "   Target: None\n",
      "   Writer: None\n",
      "   >> âœ… MATCH\n",
      "\n",
      "====================================================================================================\n",
      "ğŸ”¥ MATCH FOUND #2 (Dataset Index: 19)\n",
      "   Prompt Text: <s>[INST] You are a helpful assistant for molecular chemistry, to address tasks including molecular  ... (Identical)\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ”¹ [Input Mol Strings]\n",
      "   Target: <SELFIES> [C][C][Branch1][C][C][Branch1][C][C][C][C][=C][N][=C][C][=Branch1][Ring2][=C][Ring1][=Branch1][C][Branch2][Ring2][=Branch2][NH2+1][C][C][Branch1][C][O][C][C][C][=C][C][=C][C][=Branch1][Ring2][=C][Ring1][=Branch1][C][C][C][N][C][=C][Branch1][#Branch1][C][=C][C][Ring1][=Branch1][=O][C][=Branch1][C][=O][N][Ring2][Ring1][Branch1][C][C][Branch1][=Branch1][C][C][C][Ring1][Ring2][O][Ring2][Ring2][Ring1] </SELFIES>\n",
      "   Writer: <SELFIES> [C][C][Branch1][C][C][Branch1][C][C][C][C][=C][N][=C][C][=Branch1][Ring2][=C][Ring1][=Branch1][C][Branch2][Ring2][=Branch2][NH2+1][C][C][Branch1][C][O][C][C][C][=C][C][=C][C][=Branch1][Ring2][=C][Ring1][=Branch1][C][C][C][N][C][=C][Branch1][#Branch1][C][=C][C][Ring1][=Branch1][=O][C][=Branch1][C][=O][N][Ring2][Ring1][Branch1][C][C][Branch1][=Branch1][C][C][C][Ring1][Ring2][O][Ring2][Ring2][Ring1] </SELFIES>\n",
      "   >> âœ… MATCH\n",
      "\n",
      "ğŸ”¹ [Target Text (Label)]\n",
      "   Target: <BOOLEAN> True </BOOLEAN> </s>\n",
      "   Writer: <BOOLEAN> True </BOOLEAN> </s>\n",
      "   >> âœ… MATCH\n",
      "\n",
      "ğŸ”¹ [Graph Node Feat (x)]\n",
      "   Target: None\n",
      "   Writer: None\n",
      "   >> âœ… MATCH\n",
      "\n",
      "ğŸ”¹ [Graph Edge Index]\n",
      "   Target: None\n",
      "   Writer: None\n",
      "   >> âœ… MATCH\n",
      "\n",
      "ğŸ”¹ [Graph Edge Attr]\n",
      "   Target: None\n",
      "   Writer: None\n",
      "   >> âœ… MATCH\n",
      "\n",
      "====================================================================================================\n",
      "ğŸ”¥ MATCH FOUND #3 (Dataset Index: 29)\n",
      "   Prompt Text: <s>[INST] You are a helpful assistant for molecular chemistry, to address tasks including molecular  ... (Identical)\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ”¹ [Input Mol Strings]\n",
      "   Target: <SELFIES> [C][N][Branch2][Ring1][=Branch1][C][=Branch1][C][=O][C][C][C][=C][C][=C][C][=C][C][=C][Ring1][=Branch1][N][=C][Ring1][#Branch2][N][C][C][C][C][C][C][Ring1][=Branch1] </SELFIES>\n",
      "   Writer: <SELFIES> [C][N][Branch2][Ring1][=Branch1][C][=Branch1][C][=O][C][C][C][=C][C][=C][C][=C][C][=C][Ring1][=Branch1][N][=C][Ring1][#Branch2][N][C][C][C][C][C][C][Ring1][=Branch1] </SELFIES>\n",
      "   >> âœ… MATCH\n",
      "\n",
      "ğŸ”¹ [Target Text (Label)]\n",
      "   Target: <BOOLEAN> True </BOOLEAN> </s>\n",
      "   Writer: <BOOLEAN> True </BOOLEAN> </s>\n",
      "   >> âœ… MATCH\n",
      "\n",
      "ğŸ”¹ [Graph Node Feat (x)]\n",
      "   Target: None\n",
      "   Writer: None\n",
      "   >> âœ… MATCH\n",
      "\n",
      "ğŸ”¹ [Graph Edge Index]\n",
      "   Target: None\n",
      "   Writer: None\n",
      "   >> âœ… MATCH\n",
      "\n",
      "ğŸ”¹ [Graph Edge Attr]\n",
      "   Target: None\n",
      "   Writer: None\n",
      "   >> âœ… MATCH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_from_disk\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. ê²½ë¡œ ì„¤ì •\n",
    "# ==============================================================================\n",
    "# [Writer] Reference Dataset (ì›ë³¸)\n",
    "path_ref = \"Mol-LLM_Custom/checkpoint/mol-llm_testset\"\n",
    "\n",
    "# [Target] ë¹„êµí•  ë‚´ ë°ì´í„°ì…‹ (Download ëœ ê²ƒ)\n",
    "path_target = \"Mol-LLM_Custom/dataset/real_train/mistralai-Mistral-7B-Instruct-v0.3_string+graph_q32_test_3.3M_0415_download_InstructGraph_blank_bace\"\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (í•œ ì¤„ ì¶œë ¥ìš©)\n",
    "# ==============================================================================\n",
    "\n",
    "def format_oneline(value):\n",
    "    \"\"\"\n",
    "    Tensor, List, Dict ë“± ì–´ë–¤ ê°’ì´ ì˜¤ë”ë¼ë„ ê°•ì œë¡œ ì¤„ë°”ê¿ˆì„ ì—†ì• ê³ \n",
    "    í•œ ì¤„ì§œë¦¬ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    if value is None:\n",
    "        return \"None\"\n",
    "    \n",
    "    # Tensorë‚˜ Arrayë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        value = value.tolist()\n",
    "    elif isinstance(value, np.ndarray):\n",
    "        value = value.tolist()\n",
    "        \n",
    "    # ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "    s = str(value)\n",
    "    \n",
    "    # 1. ì¤„ë°”ê¿ˆ(\\n) ì œê±°\n",
    "    s = s.replace('\\n', '')\n",
    "    s = s.replace('\\r', '')\n",
    "    \n",
    "    # 2. íƒ­(\\t) ì œê±°\n",
    "    s = s.replace('\\t', ' ')\n",
    "    \n",
    "    # 3. ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ ì¤„ì„\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    \n",
    "    return s.strip()\n",
    "\n",
    "def get_graph_feature(item, feature_name):\n",
    "    \"\"\"\n",
    "    item['graph'] ì•ˆì— ìˆëŠ” feature_name (ì˜ˆ: x, edge_index)ì„ ì•ˆì „í•˜ê²Œ êº¼ëƒ…ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    graph_data = item.get('graph')\n",
    "    if graph_data is None:\n",
    "        return None\n",
    "\n",
    "    # graphê°€ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°\n",
    "    if isinstance(graph_data, dict):\n",
    "        return graph_data.get(feature_name)\n",
    "    \n",
    "    # graphê°€ PyG Data ê°ì²´ì¸ ê²½ìš° (ì†ì„±ìœ¼ë¡œ ì ‘ê·¼)\n",
    "    if hasattr(graph_data, feature_name):\n",
    "        return getattr(graph_data, feature_name)\n",
    "        \n",
    "    return None\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. ë©”ì¸ ë¹„êµ ë¡œì§\n",
    "# ==============================================================================\n",
    "\n",
    "def main():\n",
    "    print(\"ğŸ“‚ Loading Datasets...\")\n",
    "    ds_ref = load_from_disk(path_ref)\n",
    "    ds_target = load_from_disk(path_target)\n",
    "    \n",
    "    print(f\"   Ref Size: {len(ds_ref)}\")\n",
    "    print(f\"   Target Size: {len(ds_target)}\")\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 1. Reference Indexing (Key = prompt_text)\n",
    "    # -------------------------------------------------------\n",
    "    print(\"\\nğŸ” Indexing Reference Dataset by 'prompt_text'...\")\n",
    "    ref_lookup = {}\n",
    "    \n",
    "    # ì†ë„ë¥¼ ìœ„í•´ BACE ê´€ë ¨ ë°ì´í„°ë§Œ í•„í„°ë§í•˜ì—¬ ì¸ë±ì‹± (ì„ íƒì‚¬í•­)\n",
    "    ds_ref_filtered = ds_ref.filter(lambda x: 'bace' in str(x.get('task', '')).lower())\n",
    "    \n",
    "    for item in tqdm(ds_ref_filtered, desc=\"Building Index\"):\n",
    "        # ê³µë°± ì œê±° í›„ í‚¤ë¡œ ì‚¬ìš© (ë¯¸ì„¸í•œ ì°¨ì´ ë¬´ì‹œ)\n",
    "        p_text = item.get('prompt_text') or item.get('text', '')\n",
    "        if p_text:\n",
    "            ref_lookup[p_text.strip()] = item\n",
    "            \n",
    "    print(f\"   âœ… Indexed {len(ref_lookup)} unique prompts from Reference.\")\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 2. Target ë°ì´í„° ìˆœíšŒí•˜ë©° ë§¤ì¹­ ì‹œë„\n",
    "    # -------------------------------------------------------\n",
    "    print(\"\\nâš–ï¸  Starting Comparison (Matching logic: prompt_text)...\")\n",
    "    \n",
    "    matched_count = 0\n",
    "    max_matches_to_show = 3  # ëª‡ ê°œë‚˜ ë¹„êµí•˜ê³  ë©ˆì¶œì§€ ì„¤ì •\n",
    "    \n",
    "    # ë¹„êµí•  í•„ë“œ ëª©ë¡ ì •ì˜\n",
    "    fields_to_compare = [\n",
    "        # (í‘œì‹œ ì´ë¦„, í•„ë“œ í‚¤, ê·¸ë˜í”„ ë‚´ë¶€ ì—¬ë¶€)\n",
    "        ('Input Mol Strings', 'input_mol_strings', False), \n",
    "        ('Target Text (Label)', 'target_text', False),\n",
    "        ('Graph Node Feat (x)', 'x', True),\n",
    "        ('Graph Edge Index', 'edge_index', True),\n",
    "        ('Graph Edge Attr', 'edge_attr', True),\n",
    "    ]\n",
    "    for i, target_item in enumerate(ds_target):\n",
    "        if matched_count >= max_matches_to_show:\n",
    "            break\n",
    "            \n",
    "        # Targetì˜ prompt_text ê°€ì ¸ì˜¤ê¸°\n",
    "        tgt_prompt = target_item.get('prompt_text') or target_item.get('text', '')\n",
    "        if not tgt_prompt:\n",
    "            continue\n",
    "            \n",
    "        tgt_key = tgt_prompt.strip()\n",
    "        \n",
    "        # 1. Prompt Text ë§¤ì¹­ í™•ì¸\n",
    "        if tgt_key in ref_lookup:\n",
    "            ref_item = ref_lookup[tgt_key]\n",
    "            matched_count += 1\n",
    "            \n",
    "            print(f\"\\n{'='*100}\")\n",
    "            print(f\"ğŸ”¥ MATCH FOUND #{matched_count} (Dataset Index: {i})\")\n",
    "            print(f\"   Prompt Text: {format_oneline(tgt_prompt)[:100]} ... (Identical)\")\n",
    "            print(f\"{'='*100}\")\n",
    "            \n",
    "            # 2. ì„¸ë¶€ í•­ëª© ë¹„êµ\n",
    "            for label, field_key, is_graph in fields_to_compare:\n",
    "                if is_graph:\n",
    "                    val_tgt = get_graph_feature(target_item, field_key)\n",
    "                    val_ref = get_graph_feature(ref_item, field_key)\n",
    "                else:\n",
    "                    # input_mol_strings ë“±ì€ ì´ë¦„ì´ ì¡°ê¸ˆ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ ì˜ˆì™¸ ì²˜ë¦¬\n",
    "                    if field_key == 'input_mol_strings':\n",
    "                         val_tgt = target_item.get('input_mol_strings') or target_item.get('input_mol_string')\n",
    "                         val_ref = ref_item.get('input_mol_strings') or ref_item.get('input_mol_string')\n",
    "                    else:\n",
    "                        val_tgt = target_item.get(field_key)\n",
    "                        val_ref = ref_item.get(field_key)\n",
    "                \n",
    "                # í¬ë§·íŒ… (í•œ ì¤„ ë§Œë“¤ê¸°)\n",
    "                str_tgt = format_oneline(val_tgt)\n",
    "                str_ref = format_oneline(val_ref)\n",
    "                \n",
    "                print(f\"\\nğŸ”¹ [{label}]\")\n",
    "                print(f\"   Target: {str_tgt}\")\n",
    "                print(f\"   Writer: {str_ref}\")\n",
    "                \n",
    "                if str_tgt == str_ref:\n",
    "                    print(\"   >> âœ… MATCH\")\n",
    "                else:\n",
    "                    print(\"   >> âŒ DIFFERENT\")\n",
    "                    \n",
    "    if matched_count == 0:\n",
    "        print(\"\\nâš ï¸ No exact prompt text matches found.\")\n",
    "        print(\"   (This is expected if you are comparing the 'Swapped' dataset against the original Reference.)\")\n",
    "        print(\"   (If comparing original vs original, check if preprocessing differed.)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b309827",
   "metadata": {},
   "source": [
    "# ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d250f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "download_bace_blank = load_from_disk('Mol-LLM_Custom/dataset/real_train/mistralai-Mistral-7B-Instruct-v0.3_string+graph_q32_test_3.3M_0415_InstructGraph_blank_bace')\n",
    "len(download_bace_blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdc3c63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': [[5, 0, 4, 5, 3, 0, 2, 0, 0],\n",
       "  [5, 0, 3, 5, 0, 0, 1, 1, 1],\n",
       "  [5, 0, 3, 5, 1, 0, 1, 1, 1],\n",
       "  [5, 0, 3, 5, 1, 0, 1, 1, 1],\n",
       "  [5, 0, 3, 5, 1, 0, 1, 1, 1],\n",
       "  [5, 0, 3, 5, 1, 0, 1, 1, 1],\n",
       "  [5, 0, 3, 5, 0, 0, 1, 1, 1],\n",
       "  [5, 0, 3, 5, 0, 0, 1, 1, 1],\n",
       "  [5, 0, 3, 5, 1, 0, 1, 1, 1],\n",
       "  [5, 0, 3, 5, 1, 0, 1, 1, 1],\n",
       "  [5, 0, 3, 5, 0, 0, 1, 1, 1],\n",
       "  [6, 0, 2, 5, 0, 0, 1, 1, 1],\n",
       "  [5, 0, 3, 5, 0, 0, 1, 1, 1],\n",
       "  [6, 0, 3, 5, 2, 0, 1, 0, 0],\n",
       "  [5, 0, 3, 5, 0, 0, 1, 1, 1],\n",
       "  [5, 0, 4, 5, 2, 0, 2, 0, 0],\n",
       "  [5, 0, 4, 5, 1, 0, 2, 0, 0],\n",
       "  [5, 0, 4, 5, 3, 0, 2, 0, 0],\n",
       "  [5, 0, 3, 5, 0, 0, 1, 0, 0],\n",
       "  [7, 0, 1, 5, 0, 0, 1, 0, 0],\n",
       "  [6, 0, 3, 5, 1, 0, 1, 0, 0],\n",
       "  [5, 0, 4, 5, 2, 0, 2, 0, 0],\n",
       "  [5, 0, 4, 5, 1, 0, 2, 0, 1],\n",
       "  [5, 0, 4, 5, 2, 0, 2, 0, 1],\n",
       "  [5, 0, 4, 5, 2, 0, 2, 0, 1],\n",
       "  [7, 0, 2, 5, 0, 0, 2, 0, 1],\n",
       "  [5, 0, 4, 5, 2, 0, 2, 0, 1],\n",
       "  [5, 0, 4, 5, 2, 0, 2, 0, 1],\n",
       "  [5, 0, 3, 5, 1, 0, 1, 1, 1],\n",
       "  [5, 0, 3, 5, 0, 0, 1, 1, 1],\n",
       "  [5, 0, 3, 5, 1, 0, 1, 1, 1]],\n",
       " 'edge_index': [[0,\n",
       "   1,\n",
       "   1,\n",
       "   2,\n",
       "   2,\n",
       "   3,\n",
       "   3,\n",
       "   4,\n",
       "   4,\n",
       "   5,\n",
       "   5,\n",
       "   6,\n",
       "   6,\n",
       "   7,\n",
       "   7,\n",
       "   8,\n",
       "   8,\n",
       "   9,\n",
       "   9,\n",
       "   10,\n",
       "   10,\n",
       "   11,\n",
       "   11,\n",
       "   12,\n",
       "   12,\n",
       "   13,\n",
       "   12,\n",
       "   14,\n",
       "   14,\n",
       "   15,\n",
       "   15,\n",
       "   16,\n",
       "   16,\n",
       "   17,\n",
       "   16,\n",
       "   18,\n",
       "   18,\n",
       "   19,\n",
       "   18,\n",
       "   20,\n",
       "   20,\n",
       "   21,\n",
       "   21,\n",
       "   22,\n",
       "   22,\n",
       "   23,\n",
       "   23,\n",
       "   24,\n",
       "   24,\n",
       "   25,\n",
       "   25,\n",
       "   26,\n",
       "   26,\n",
       "   27,\n",
       "   14,\n",
       "   28,\n",
       "   28,\n",
       "   29,\n",
       "   29,\n",
       "   30,\n",
       "   6,\n",
       "   1,\n",
       "   30,\n",
       "   7,\n",
       "   29,\n",
       "   10,\n",
       "   27,\n",
       "   22],\n",
       "  [1,\n",
       "   0,\n",
       "   2,\n",
       "   1,\n",
       "   3,\n",
       "   2,\n",
       "   4,\n",
       "   3,\n",
       "   5,\n",
       "   4,\n",
       "   6,\n",
       "   5,\n",
       "   7,\n",
       "   6,\n",
       "   8,\n",
       "   7,\n",
       "   9,\n",
       "   8,\n",
       "   10,\n",
       "   9,\n",
       "   11,\n",
       "   10,\n",
       "   12,\n",
       "   11,\n",
       "   13,\n",
       "   12,\n",
       "   14,\n",
       "   12,\n",
       "   15,\n",
       "   14,\n",
       "   16,\n",
       "   15,\n",
       "   17,\n",
       "   16,\n",
       "   18,\n",
       "   16,\n",
       "   19,\n",
       "   18,\n",
       "   20,\n",
       "   18,\n",
       "   21,\n",
       "   20,\n",
       "   22,\n",
       "   21,\n",
       "   23,\n",
       "   22,\n",
       "   24,\n",
       "   23,\n",
       "   25,\n",
       "   24,\n",
       "   26,\n",
       "   25,\n",
       "   27,\n",
       "   26,\n",
       "   28,\n",
       "   14,\n",
       "   29,\n",
       "   28,\n",
       "   30,\n",
       "   29,\n",
       "   1,\n",
       "   6,\n",
       "   7,\n",
       "   30,\n",
       "   10,\n",
       "   29,\n",
       "   22,\n",
       "   27]],\n",
       " 'edge_attr': [[0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [1, 0, 1],\n",
       "  [1, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0]],\n",
       " 'label': '<BOOLEAN> True </BOOLEAN>',\n",
       " 'input_mol_string': '<SELFIES> [C][C][=C][C][=C][C][=C][Ring1][=Branch1][C][=C][C][=C][N][=C][Branch1][C][N][C][Branch2][Ring1][Ring2][C][C][Branch1][C][C][C][=Branch1][C][=O][N][C][C][C][C][O][C][C][Ring1][=Branch1][=C][C][Ring2][Ring1][Ring2][=C][Ring2][Ring1][Branch2] </SELFIES>',\n",
       " 'task_subtask_pair': 'bace',\n",
       " 'instruction': 'A molecule <INPUT> is given; what could be the biological activity against BACE-1?',\n",
       " 'task': 'bace',\n",
       " 'additional_x': [[5, 0, 4, 5, 3, 0, 2, 0, 0], [5, 0, 4, 5, 3, 0, 2, 0, 0]],\n",
       " 'additional_edge_index': [[0, 1], [1, 0]],\n",
       " 'additional_edge_attr': [[0, 0, 0], [0, 0, 0]],\n",
       " 'prompt_text': '<s>[INST] You are a helpful assistant for molecular chemistry, to address tasks including molecular property classification, molecular property regression, chemical reaction prediction, molecule captioning, molecule generation. \\n\\nA molecule <SELFIES> [C][C][=C][C][=C][C][=C][Ring1][=Branch1][C][=C][C][=C][N][=C][Branch1][C][N][C][Branch2][Ring1][Ring2][C][C][Branch1][C][C][C][=Branch1][C][=O][N][C][C][C][C][O][C][C][Ring1][=Branch1][=C][C][Ring2][Ring1][Ring2][=C][Ring2][Ring1][Branch2] </SELFIES><GRAPH><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol></GRAPH> is given; what could be the biological activity against BACE-1? [/INST]',\n",
       " 'target_text': '<BOOLEAN> True </BOOLEAN> </s>'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_bace_blank[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "469192f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_from_disk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m writer \u001b[38;5;241m=\u001b[39m \u001b[43mload_from_disk\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMol-LLM_Custom/checkpoint/mol-llm_testset\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m x : x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbace\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m writer[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_from_disk' is not defined"
     ]
    }
   ],
   "source": [
    "writer = load_from_disk('Mol-LLM_Custom/checkpoint/mol-llm_testset').filter(lambda x : x['task'] == 'bace')\n",
    "writer[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "679071e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'writer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwriter\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'writer' is not defined"
     ]
    }
   ],
   "source": [
    "writer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42689558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MolDA_CHJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
