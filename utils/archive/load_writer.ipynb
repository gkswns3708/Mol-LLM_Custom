{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3ffb7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/miniconda3/envs/MolDA_CHJ/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Filter: 100%|██████████| 3010/3010 [00:01<00:00, 1768.63 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk, load_dataset\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# 데이터셋 로드 및 필터링 (기존 코드)\n",
    "writer_test_dataset = load_from_disk(\"Mol-LLM_Custom/dataset/real_train(download_v1)/mistralai-Mistral-7B-Instruct-v0.3_string+graph_q32_test_3.3M_0415_writer\")\n",
    "writer_forward_reaction_prediction_test_dataset = writer_test_dataset.filter(lambda x : 'forward_reaction_prediction' in x['task'] )\n",
    "\n",
    "download_test_dataset = load_from_disk(\"Mol-LLM_Custom/dataset/real_train/mistralai-Mistral-7B-Instruct-v0.3_string+graph_q32_test_3.3M_0415\")\n",
    "download_forward_reaction_prediction_test_dataset = download_test_dataset.filter(lambda x : 'forward_reaction_prediction' in x['task'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7640ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "additional_edge_attr: [[1, 0, 1], [1, 0, 1], [0, 0, 0], [0, 0, 0], [0, 0, 1], [0, 0, 1], [1, 0, 1], [1, 0, 1], [0, 0, 0], [0, 0, 0], [1, 0, 1], [1, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 1], [0, 0, 1], [1, 0, 1], [1, 0, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]]\n",
      "additional_edge_index: [[0, 1, 1, 2, 1, 3, 3, 4, 3, 5, 6, 7, 7, 8, 7, 9, 9, 10, 10, 11, 11, 12, 11, 13, 11, 14, 15, 16, 16, 17, 16, 18, 18, 19, 20, 21, 21, 22], [1, 0, 2, 1, 3, 1, 4, 3, 5, 3, 7, 6, 8, 7, 9, 7, 10, 9, 11, 10, 12, 11, 13, 11, 14, 11, 16, 15, 17, 16, 18, 16, 19, 18, 21, 20, 22, 21]]\n",
      "additional_x: [[7, 0, 1, 5, 0, 0, 1, 0, 0], [5, 0, 3, 5, 0, 0, 1, 0, 0], [16, 0, 1, 5, 0, 0, 2, 0, 0], [5, 0, 3, 5, 0, 0, 1, 0, 0], [7, 0, 1, 5, 0, 0, 1, 0, 0], [16, 0, 1, 5, 0, 0, 2, 0, 0], [7, 0, 1, 5, 0, 0, 1, 0, 0], [5, 0, 3, 5, 0, 0, 1, 0, 0], [7, 0, 2, 5, 1, 0, 1, 0, 0], [5, 0, 4, 5, 2, 0, 2, 0, 0], [5, 0, 4, 5, 2, 0, 2, 0, 0], [5, 0, 4, 5, 0, 0, 2, 0, 0], [8, 0, 1, 5, 0, 0, 2, 0, 0], [8, 0, 1, 5, 0, 0, 2, 0, 0], [8, 0, 1, 5, 0, 0, 2, 0, 0], [5, 0, 4, 5, 3, 0, 2, 0, 0], [6, 0, 3, 5, 0, 0, 1, 0, 0], [5, 0, 4, 5, 3, 0, 2, 0, 0], [5, 0, 3, 5, 1, 0, 1, 0, 0], [7, 0, 1, 5, 0, 0, 1, 0, 0], [16, 0, 1, 5, 0, 0, 2, 0, 0], [5, 0, 4, 5, 2, 0, 2, 0, 0], [16, 0, 1, 5, 0, 0, 2, 0, 0]]\n",
      "edge_attr: [[1, 0, 1], [1, 0, 1], [0, 0, 0], [0, 0, 0], [0, 0, 1], [0, 0, 1], [1, 0, 1], [1, 0, 1], [0, 0, 0], [0, 0, 0], [1, 0, 1], [1, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 1], [0, 0, 1], [1, 0, 1], [1, 0, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]]\n",
      "edge_index: [[0, 1, 1, 2, 1, 3, 3, 4, 3, 5, 6, 7, 7, 8, 7, 9, 9, 10, 10, 11, 11, 12, 11, 13, 11, 14, 15, 16, 16, 17, 16, 18, 18, 19, 20, 21, 21, 22], [1, 0, 2, 1, 3, 1, 4, 3, 5, 3, 7, 6, 8, 7, 9, 7, 10, 9, 11, 10, 12, 11, 13, 11, 14, 11, 16, 15, 17, 16, 18, 16, 19, 18, 21, 20, 22, 21]]\n",
      "input_mol_string: <SELFIES> [C][N][Branch1][C][C][C][=O].[Cl][C][Cl].[O][=C][Branch1][C][Cl][C][=Branch1][C][=O][Cl].[O][=C][Branch1][C][O][C][C][C][Branch1][C][F][Branch1][C][F][F] </SELFIES>\n",
      "prompt_text: <s>[INST] You are a helpful assistant for molecular chemistry, to address tasks including molecular property classification, molecular property regression, chemical reaction prediction, molecule captioning, molecule generation. \n",
      "\n",
      "Given the following reactants and reagents, please provide a possible product. <SELFIES> [C][N][Branch1][C][C][C][=O].[Cl][C][Cl].[O][=C][Branch1][C][Cl][C][=Branch1][C][=O][Cl].[O][=C][Branch1][C][O][C][C][C][Branch1][C][F][Branch1][C][F][F] </SELFIES><GRAPH><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol></GRAPH> [/INST] \n",
      "target_text: <SELFIES>[O][=C][Branch1][C][Cl][C][C][C][Branch1][C][F][Branch1][C][F][F]</SELFIES> </s>\n",
      "task: presto-forward_reaction_prediction\n",
      "x: [[7, 0, 1, 5, 0, 0, 1, 0, 0], [5, 0, 3, 5, 0, 0, 1, 0, 0], [16, 0, 1, 5, 0, 0, 2, 0, 0], [5, 0, 3, 5, 0, 0, 1, 0, 0], [7, 0, 1, 5, 0, 0, 1, 0, 0], [16, 0, 1, 5, 0, 0, 2, 0, 0], [7, 0, 1, 5, 0, 0, 1, 0, 0], [5, 0, 3, 5, 0, 0, 1, 0, 0], [7, 0, 2, 5, 1, 0, 1, 0, 0], [5, 0, 4, 5, 2, 0, 2, 0, 0], [5, 0, 4, 5, 2, 0, 2, 0, 0], [5, 0, 4, 5, 0, 0, 2, 0, 0], [8, 0, 1, 5, 0, 0, 2, 0, 0], [8, 0, 1, 5, 0, 0, 2, 0, 0], [8, 0, 1, 5, 0, 0, 2, 0, 0], [5, 0, 4, 5, 3, 0, 2, 0, 0], [6, 0, 3, 5, 0, 0, 1, 0, 0], [5, 0, 4, 5, 3, 0, 2, 0, 0], [5, 0, 3, 5, 1, 0, 1, 0, 0], [7, 0, 1, 5, 0, 0, 1, 0, 0], [16, 0, 1, 5, 0, 0, 2, 0, 0], [5, 0, 4, 5, 2, 0, 2, 0, 0], [16, 0, 1, 5, 0, 0, 2, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(writer_forward_reaction_prediction_test_dataset[0].items()):\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daba3f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Datasets...\n",
      "Writer Dataset Size: 58757\n",
      "My Dataset Size: 3010\n",
      "\n",
      "Indexing Writer Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing Writer: 100%|██████████| 58757/58757 [00:32<00:00, 1834.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing My Dataset against Writer Index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning My Dataset: 100%|██████████| 3010/3010 [00:01<00:00, 1780.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " Comparison Summary\n",
      "==================================================\n",
      "Total Target Items in My Dataset: 3010\n",
      "Matched with Writer Dataset:      0\n",
      "Missing in Writer Dataset:        3010\n",
      "==================================================\n",
      "No matches found for the specified tasks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_from_disk\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# 1. 설정 및 데이터 로드\n",
    "writer_path = \"Mol-LLM_Custom/dataset/real_train(download_v1)/mistralai-Mistral-7B-Instruct-v0.3_string+graph_q32_test_3.3M_0415_writer\"\n",
    "my_path = \"Mol-LLM_Custom/dataset/real_train/mistralai-Mistral-7B-Instruct-v0.3_string+graph_q32_test_3.3M_0415\"\n",
    "\n",
    "print(\"Loading Datasets...\")\n",
    "writer_dataset = load_from_disk(writer_path)\n",
    "my_dataset = load_from_disk(my_path)\n",
    "\n",
    "print(f\"Writer Dataset Size: {len(writer_dataset)}\")\n",
    "print(f\"My Dataset Size: {len(my_dataset)}\")\n",
    "\n",
    "# 2. 타겟 Task 정의 (비교하고 싶은 Task 키워드)\n",
    "target_keywords = [\n",
    "    \"forward_reaction_prediction\",\n",
    "    \"qm9_homo\",\n",
    "    \"qm9_homo_lumo_gap\", # 순서 중요: qm9_homo가 qm9_homo_lumo_gap에 매칭되지 않도록 긴 것을 먼저 쓰거나 정확히 일치시킴\n",
    "    \"qm9_lumo\"\n",
    "]\n",
    "\n",
    "\n",
    "def get_task_key(task_name):\n",
    "    # 데이터셋의 task 이름(예: presto-forward...)에서 핵심 키워드만 추출하여 통일\n",
    "    for keyword in target_keywords:\n",
    "        if keyword in task_name:\n",
    "            # qm9_homo와 qm9_homo_lumo_gap 구분을 위해 정확한 매칭 확인\n",
    "            if keyword == \"qm9_homo\" and \"gap\" in task_name:\n",
    "                continue\n",
    "            return keyword\n",
    "    return None\n",
    "\n",
    "# 4. Writer 데이터셋 Indexing (Hash Map 구축)\n",
    "# Key: (Task_Keyword, Normalized_Input_String) -> Value: Data Instance\n",
    "print(\"\\nIndexing Writer Dataset...\")\n",
    "writer_index = {}\n",
    "\n",
    "for i in tqdm(range(len(writer_dataset)), desc=\"Indexing Writer\"):\n",
    "    item = writer_dataset[i]\n",
    "    raw_task = item['task']\n",
    "    \n",
    "    task_key = get_task_key(raw_task)\n",
    "    if task_key:\n",
    "        norm_input = item['input_mol_string']\n",
    "        # 검색 속도를 위해 Dictionary에 저장\n",
    "        writer_index[(task_key, norm_input)] = {\n",
    "            \"target_text\": item['target_text'],\n",
    "            \"original_task\": raw_task,\n",
    "            \"index\": i\n",
    "        }\n",
    "\n",
    "# 5. 내 데이터셋과 비교 (Compare)\n",
    "print(\"\\nComparing My Dataset against Writer Index...\")\n",
    "matches = []\n",
    "matched_count = 0\n",
    "missing_count = 0\n",
    "\n",
    "for i in tqdm(range(len(my_dataset)), desc=\"Scanning My Dataset\"):\n",
    "    item = my_dataset[i]\n",
    "    raw_task = item['task']\n",
    "    \n",
    "    task_key = get_task_key(raw_task)\n",
    "    if task_key:\n",
    "        norm_input = item['input_mol_string']\n",
    "        \n",
    "        # Writer Index에 존재하는지 확인\n",
    "        if (task_key, norm_input) in writer_index:\n",
    "            ref_data = writer_index[(task_key, norm_input)]\n",
    "            \n",
    "            # 결과 저장\n",
    "            matches.append({\n",
    "                \"Task Group\": task_key,\n",
    "                \"My Task Name\": raw_task,\n",
    "                \"Match Found\": True,\n",
    "                \"Input Molecule (Snippet)\": norm_input, # 너무 기니까 잘라서 표시\n",
    "                \"Writer Target\": ref_data['target_text'],\n",
    "                \"My Target\": item['target_text'],\n",
    "                \"Target Match\": ref_data['target_text'] == item['target_text'] # Target 값도 완전히 같은지 확인\n",
    "            })\n",
    "            matched_count += 1\n",
    "        else:\n",
    "            # 내 데이터에는 있는데 Writer에는 없는 경우 (필요시 주석 해제하여 확인)\n",
    "            # matches.append({\n",
    "            #     \"Task Group\": task_key,\n",
    "            #     \"My Task Name\": raw_task,\n",
    "            #     \"Match Found\": False,\n",
    "            #     \"Input Molecule (Snippet)\": norm_input[:50] + \"...\",\n",
    "            #     \"Writer Target\": \"N/A\",\n",
    "            #     \"My Target\": item['target_text'],\n",
    "            #     \"Target Match\": False\n",
    "            # })\n",
    "            missing_count += 1\n",
    "\n",
    "# 6. 결과 출력 (Pandas DataFrame)\n",
    "df = pd.DataFrame(matches)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\" Comparison Summary\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total Target Items in My Dataset: {matched_count + missing_count}\")\n",
    "print(f\"Matched with Writer Dataset:      {matched_count}\")\n",
    "print(f\"Missing in Writer Dataset:        {missing_count}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if not df.empty:\n",
    "    print(\"\\n[Sample Matches (First 10 rows)]\")\n",
    "    # 가독성을 위해 컬럼 선택 및 출력 옵션 조정\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    display_cols = [\"Task Group\", \"Input Molecule (Snippet)\", \"Writer Target\", \"My Target\", \"Target Match\"]\n",
    "    print(df[display_cols].head(10).to_markdown(index=False))\n",
    "\n",
    "    # Target 값이 서로 다른 경우가 있는지 확인\n",
    "    mismatch_targets = df[df[\"Target Match\"] == False]\n",
    "    if not mismatch_targets.empty:\n",
    "        print(\"\\n[Warning] Input matched but Target value is different:\")\n",
    "        print(mismatch_targets[display_cols].head().to_markdown(index=False))\n",
    "    else:\n",
    "        print(\"\\n[Success] All matched inputs have identical target values.\")\n",
    "        \n",
    "    # 결과를 CSV로 저장 (선택 사항)\n",
    "    # df.to_csv(\"dataset_comparison_result.csv\", index=False)\n",
    "    # print(\"\\nDetailed result saved to 'dataset_comparison_result.csv'\")\n",
    "else:\n",
    "    print(\"No matches found for the specified tasks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a7b85cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Datasets...\n",
      "\n",
      "Indexing Writer Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|██████████| 58757/58757 [00:32<00:00, 1805.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing Mismatches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: 100%|██████████| 3010/3010 [00:01<00:00, 1731.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " Mismatch Analysis Report\n",
      "============================================================\n",
      "Total Mismatches found (Recovered via Norm): 2328\n",
      "\n",
      "[Top 5 Mismatch Examples - Character Level]\n",
      "Tip: Look at 'repr()' output. '\\n' is newline, ' ' is space.\n",
      "\n",
      "--- Example 1 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 161, Writer: 163\n",
      "\n",
      "--- Example 2 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 172, Writer: 174\n",
      "\n",
      "--- Example 3 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 336, Writer: 338\n",
      "\n",
      "--- Example 4 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 346, Writer: 348\n",
      "\n",
      "--- Example 5 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 1039, Writer: 1041\n",
      "\n",
      "--- Example 6 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 157, Writer: 159\n",
      "\n",
      "--- Example 7 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 311, Writer: 313\n",
      "\n",
      "--- Example 8 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 620, Writer: 622\n",
      "\n",
      "--- Example 9 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 400, Writer: 402\n",
      "\n",
      "--- Example 10 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 426, Writer: 428\n",
      "\n",
      "--- Example 11 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 270, Writer: 272\n",
      "\n",
      "--- Example 12 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 250, Writer: 252\n",
      "\n",
      "--- Example 13 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 157, Writer: 159\n",
      "\n",
      "--- Example 14 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 798, Writer: 800\n",
      "\n",
      "--- Example 15 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 569, Writer: 571\n",
      "\n",
      "--- Example 16 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 386, Writer: 388\n",
      "\n",
      "--- Example 17 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 215, Writer: 217\n",
      "\n",
      "--- Example 18 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 287, Writer: 289\n",
      "\n",
      "--- Example 19 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 358, Writer: 360\n",
      "\n",
      "--- Example 20 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 342, Writer: 344\n",
      "\n",
      "--- Example 21 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 539, Writer: 541\n",
      "\n",
      "--- Example 22 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 299, Writer: 301\n",
      "\n",
      "--- Example 23 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 258, Writer: 260\n",
      "\n",
      "--- Example 24 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 496, Writer: 498\n",
      "\n",
      "--- Example 25 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 263, Writer: 265\n",
      "\n",
      "--- Example 26 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 230, Writer: 232\n",
      "\n",
      "--- Example 27 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 335, Writer: 337\n",
      "\n",
      "--- Example 28 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 122, Writer: 124\n",
      "\n",
      "--- Example 29 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 342, Writer: 344\n",
      "\n",
      "--- Example 30 (Task: forward_reaction_prediction) ---\n",
      "Difference starts at index: 9\n",
      "My Raw Snippet    : ''\n",
      "Writer Raw Snippet: ''\n",
      "Length -> My: 384, Writer: 386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_from_disk\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import difflib\n",
    "\n",
    "# 1. 설정 및 데이터 로드\n",
    "writer_path = \"Mol-LLM_Custom/dataset/real_train(download_v1)/mistralai-Mistral-7B-Instruct-v0.3_string+graph_q32_test_3.3M_0415_writer\"\n",
    "my_path = \"Mol-LLM_Custom/dataset/real_train/mistralai-Mistral-7B-Instruct-v0.3_string+graph_q32_test_3.3M_0415\"\n",
    "\n",
    "print(\"Loading Datasets...\")\n",
    "writer_dataset = load_from_disk(writer_path)\n",
    "my_dataset = load_from_disk(my_path)\n",
    "\n",
    "# 2. 타겟 Task 정의\n",
    "target_keywords = [\n",
    "    \"forward_reaction_prediction\",\n",
    "    \"qm9_homo\",\n",
    "    \"qm9_homo_lumo_gap\",\n",
    "    \"qm9_lumo\"\n",
    "]\n",
    "\n",
    "# 3. 연결고리가 될 Normalize 함수 (이걸 거치면 같아진다고 가정)\n",
    "def normalize_input(text):\n",
    "    if text is None: return \"\"\n",
    "    # 태그 제거 및 공백 정규화\n",
    "    text_clean = text.replace(\"<SELFIES>\", \"\").replace(\"</SELFIES>\", \"\")\n",
    "    return re.sub(r'\\s+', ' ', text_clean).strip()\n",
    "\n",
    "def get_task_key(task_name):\n",
    "    for keyword in target_keywords:\n",
    "        if keyword in task_name:\n",
    "            if keyword == \"qm9_homo\" and \"gap\" in task_name: continue\n",
    "            return keyword\n",
    "    return None\n",
    "\n",
    "# 4. Writer 데이터셋 Indexing (Key: Normalized String -> Value: Raw String)\n",
    "print(\"\\nIndexing Writer Dataset...\")\n",
    "writer_map = {}\n",
    "\n",
    "for i in tqdm(range(len(writer_dataset)), desc=\"Indexing\"):\n",
    "    item = writer_dataset[i]\n",
    "    raw_task = item['task']\n",
    "    task_key = get_task_key(raw_task)\n",
    "    \n",
    "    if task_key:\n",
    "        norm_key = normalize_input(item['input_mol_string'])\n",
    "        # Raw String을 저장해둠\n",
    "        writer_map[(task_key, norm_key)] = item['input_mol_string']\n",
    "\n",
    "# 5. 불일치 원인 상세 분석\n",
    "print(\"\\nAnalyzing Mismatches...\")\n",
    "analysis_results = []\n",
    "inspect_count = 0\n",
    "\n",
    "for i in tqdm(range(len(my_dataset)), desc=\"Scanning\"):\n",
    "    item = my_dataset[i]\n",
    "    raw_task = item['task']\n",
    "    task_key = get_task_key(raw_task)\n",
    "    \n",
    "    if task_key:\n",
    "        my_raw = item['input_mol_string']\n",
    "        norm_key = normalize_input(my_raw)\n",
    "        \n",
    "        # 1. Normalize로는 매칭이 되는 경우 (Recovered Match)\n",
    "        if (task_key, norm_key) in writer_map:\n",
    "            writer_raw = writer_map[(task_key, norm_key)]\n",
    "            \n",
    "            # 2. 하지만 Raw String은 서로 다른 경우 -> 분석 대상\n",
    "            if my_raw != writer_raw:\n",
    "                inspect_count += 1\n",
    "                \n",
    "                # 어디서부터 달라지는지 인덱스 찾기\n",
    "                diff_idx = 0\n",
    "                min_len = min(len(my_raw), len(writer_raw))\n",
    "                while diff_idx < min_len and my_raw[diff_idx] == writer_raw[diff_idx]:\n",
    "                    diff_idx += 1\n",
    "                \n",
    "                # 차이점 기록\n",
    "                analysis_results.append({\n",
    "                    \"Task\": raw_task,\n",
    "                    \"Index\": i,\n",
    "                    \"Diff Index\": diff_idx,\n",
    "                    \"My Raw (Snippet)\": repr(my_raw[diff_idx-10:diff_idx+20]), # repr로 공백 문자 확인\n",
    "                    \"Writer Raw (Snippet)\": repr(writer_raw[diff_idx-10:diff_idx+20]),\n",
    "                    \"Full My Raw\": my_raw,\n",
    "                    \"Full Writer Raw\": writer_raw\n",
    "                })\n",
    "        else:\n",
    "            # 아예 Normalize로도 매칭 안되는 경우 (데이터 누락 등)\n",
    "            pass\n",
    "\n",
    "# 6. 결과 리포트\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\" Mismatch Analysis Report\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Mismatches found (Recovered via Norm): {len(analysis_results)}\")\n",
    "\n",
    "if len(analysis_results) > 0:\n",
    "    print(\"\\n[Top 5 Mismatch Examples - Character Level]\")\n",
    "    print(\"Tip: Look at 'repr()' output. '\\\\n' is newline, ' ' is space.\")\n",
    "    \n",
    "    for idx, row in enumerate(analysis_results[:30]):\n",
    "        print(f\"\\n--- Example {idx+1} (Task: {row['Task']}) ---\")\n",
    "        print(f\"Difference starts at index: {row['Diff Index']}\")\n",
    "        \n",
    "        # repr()을 사용하여 눈에 안보이는 문자까지 출력\n",
    "        print(f\"My Raw Snippet    : {row['My Raw (Snippet)']}\")\n",
    "        print(f\"Writer Raw Snippet: {row['Writer Raw (Snippet)']}\")\n",
    "        \n",
    "        # 전체 문자열 길이 비교\n",
    "        print(f\"Length -> My: {len(row['Full My Raw'])}, Writer: {len(row['Full Writer Raw'])}\")\n",
    "        \n",
    "        # 간단한 설명 추론\n",
    "        m_snip = row['My Raw (Snippet)']\n",
    "        w_snip = row['Writer Raw (Snippet)']\n",
    "        if \"<SELFIES> \" in m_snip and \"<SELFIES>[\" in w_snip:\n",
    "            print(\">> DIAGNOSIS: Spacing after tag (<SELFIES> vs <SELFIES>[)\")\n",
    "        elif \" \" in m_snip and \"  \" in w_snip:\n",
    "            print(\">> DIAGNOSIS: Double space issue\")\n",
    "        elif \"\\\\n\" in m_snip or \"\\\\n\" in w_snip:\n",
    "            print(\">> DIAGNOSIS: Newline character difference\")\n",
    "            \n",
    "else:\n",
    "    print(\"Great! No discrepancies found between normalized matches.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb395a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Datasets...\n",
      "Indexing Writer Dataset...\n",
      "\n",
      "Searching for mismatches...\n",
      "No mismatches found in the scanned range.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_from_disk\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# 1. 경로 설정\n",
    "writer_path = \"Mol-LLM_Custom/dataset/real_train(download_v1)/mistralai-Mistral-7B-Instruct-v0.3_string+graph_q32_test_3.3M_0415_writer\"\n",
    "my_path = \"Mol-LLM_Custom/dataset/real_train/mistralai-Mistral-7B-Instruct-v0.3_string+graph_q32_test_3.3M_0415\"\n",
    "\n",
    "print(\"Loading Datasets...\")\n",
    "writer_dataset = load_from_disk(writer_path)\n",
    "my_dataset = load_from_disk(my_path)\n",
    "\n",
    "# 2. 비교를 위한 타겟 Task 및 Normalize 함수\n",
    "target_keywords = [\"forward_reaction_prediction\", \"qm9_homo\", \"qm9_homo_lumo_gap\", \"qm9_lumo\"]\n",
    "\n",
    "# def normalize_input(text):\n",
    "#     if text is None: return \"\"\n",
    "#     # 태그, 공백, 줄바꿈 모두 제거하여 순수 텍스트만 남김\n",
    "#     text = text.replace(\"<SELFIES>\", \"\").replace(\"</SELFIES>\", \"\")\n",
    "#     return re.sub(r'\\s+', '', text).strip()\n",
    "\n",
    "def get_task_key(task_name):\n",
    "    for keyword in target_keywords:\n",
    "        if keyword in task_name:\n",
    "            if keyword == \"qm9_homo\" and \"gap\" in task_name: continue\n",
    "            return keyword\n",
    "    return None\n",
    "\n",
    "# 3. Writer 데이터셋 Indexing (매칭 짝을 찾기 위함)\n",
    "print(\"Indexing Writer Dataset...\")\n",
    "writer_map = {}\n",
    "# 너무 오래 걸리지 않게, 비교용으로 앞쪽 5000개만 스캔해서 Indexing (충분함)\n",
    "for i in range(min(len(writer_dataset), 10000)):\n",
    "    item = writer_dataset[i]\n",
    "    task_key = get_task_key(item['task'])\n",
    "    if task_key:\n",
    "        norm_key = item['input_mol_string']\n",
    "        writer_map[(task_key, norm_key)] = item['input_mol_string']\n",
    "\n",
    "# 4. 내 데이터셋을 순회하며 불일치 샘플 전체 출력\n",
    "print(\"\\nSearching for mismatches...\")\n",
    "found_count = 0\n",
    "\n",
    "for i in range(len(my_dataset)):\n",
    "    item = my_dataset[i]\n",
    "    task_key = get_task_key(item['task'])\n",
    "    \n",
    "    if task_key:\n",
    "        my_raw = item['input_mol_string']\n",
    "        norm_key = my_raw\n",
    "        \n",
    "        # Normalize하면 같은데, Raw가 다른 경우 발견!\n",
    "        if (task_key, norm_key) in writer_map:\n",
    "            writer_raw = writer_map[(task_key, norm_key)]\n",
    "            \n",
    "            if my_raw != writer_raw:\n",
    "                found_count += 1\n",
    "                \n",
    "                print(\"\\n\" + \"=\"*80)\n",
    "                print(f\" MISMATCH FOUND (Sample Index: {i}) | Task: {item['task']}\")\n",
    "                print(\"=\"*80)\n",
    "                \n",
    "                # 차이나는 지점 찾기\n",
    "                diff_idx = 0\n",
    "                min_len = min(len(my_raw), len(writer_raw))\n",
    "                while diff_idx < min_len and my_raw[diff_idx] == writer_raw[diff_idx]:\n",
    "                    diff_idx += 1\n",
    "                \n",
    "                print(f\">> Difference starts at index: {diff_idx}\")\n",
    "                print(f\">> Character at diff index (Writer): {repr(writer_raw[diff_idx]) if diff_idx < len(writer_raw) else 'End of String'}\")\n",
    "                print(f\">> Character at diff index (My)    : {repr(my_raw[diff_idx]) if diff_idx < len(my_raw) else 'End of String'}\")\n",
    "                \n",
    "                print(\"-\" * 80)\n",
    "                print(\" [WRITER DATASET SAMPLE - FULL CONTENT]\")\n",
    "                print(\"-\" * 80)\n",
    "                # repr()을 사용하여 공백, 줄바꿈 등을 명시적으로 출력\n",
    "                print(repr(writer_raw))\n",
    "                \n",
    "                print(\"\\n\" + \"-\" * 80)\n",
    "                print(\" [MY DATASET SAMPLE - FULL CONTENT]\")\n",
    "                print(\"-\" * 80)\n",
    "                print(repr(my_raw))\n",
    "                print(\"=\"*80 + \"\\n\")\n",
    "                \n",
    "                # 하나만 보고 싶으면 break, 몇 개 더 보고 싶으면 숫자 조절\n",
    "                if found_count >= 1: \n",
    "                    print(\"Stopped after printing 1 example.\")\n",
    "                    break\n",
    "\n",
    "if found_count == 0:\n",
    "    print(\"No mismatches found in the scanned range.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eed84882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': [[5, 0, 4, 5, 3, 0, 2, 0, 0],\n",
       "  [5, 0, 4, 5, 2, 0, 2, 0, 0],\n",
       "  [52, 0, 1, 5, 0, 0, 2, 0, 0],\n",
       "  [7, 0, 1, 5, 0, 0, 1, 0, 0],\n",
       "  [5, 0, 3, 5, 0, 0, 1, 0, 0],\n",
       "  [7, 0, 2, 5, 1, 0, 1, 0, 0],\n",
       "  [5, 0, 3, 5, 0, 0, 1, 1, 1],\n",
       "  [5, 0, 3, 5, 1, 0, 1, 1, 1],\n",
       "  [5, 0, 3, 5, 1, 0, 1, 1, 1],\n",
       "  [5, 0, 3, 5, 1, 0, 1, 1, 1],\n",
       "  [5, 0, 3, 5, 1, 0, 1, 1, 1],\n",
       "  [5, 0, 3, 5, 0, 0, 1, 1, 1],\n",
       "  [34, 0, 1, 5, 0, 0, 2, 0, 0],\n",
       "  [5, 0, 4, 5, 3, 0, 2, 0, 0],\n",
       "  [6, 0, 3, 5, 0, 0, 1, 0, 0],\n",
       "  [5, 0, 4, 5, 3, 0, 2, 0, 0],\n",
       "  [5, 0, 3, 5, 1, 0, 1, 0, 0],\n",
       "  [7, 0, 1, 5, 0, 0, 1, 0, 0],\n",
       "  [7, 0, 2, 5, 2, 0, 2, 0, 0],\n",
       "  [7, 0, 1, 5, 0, 0, 1, 0, 0],\n",
       "  [5, 0, 3, 5, 0, 0, 1, 0, 0],\n",
       "  [7, 0, 1, 4, 0, 0, 1, 0, 0],\n",
       "  [7, 0, 2, 5, 1, 0, 1, 0, 0],\n",
       "  [10, 0, 0, 6, 0, 0, 5, 0, 0]],\n",
       " 'edge_index': [[0,\n",
       "   1,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   4,\n",
       "   5,\n",
       "   4,\n",
       "   6,\n",
       "   6,\n",
       "   7,\n",
       "   7,\n",
       "   8,\n",
       "   8,\n",
       "   9,\n",
       "   9,\n",
       "   10,\n",
       "   10,\n",
       "   11,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   14,\n",
       "   15,\n",
       "   14,\n",
       "   16,\n",
       "   16,\n",
       "   17,\n",
       "   19,\n",
       "   20,\n",
       "   20,\n",
       "   21,\n",
       "   20,\n",
       "   22,\n",
       "   11,\n",
       "   6],\n",
       "  [1,\n",
       "   0,\n",
       "   2,\n",
       "   1,\n",
       "   4,\n",
       "   3,\n",
       "   5,\n",
       "   4,\n",
       "   6,\n",
       "   4,\n",
       "   7,\n",
       "   6,\n",
       "   8,\n",
       "   7,\n",
       "   9,\n",
       "   8,\n",
       "   10,\n",
       "   9,\n",
       "   11,\n",
       "   10,\n",
       "   12,\n",
       "   11,\n",
       "   14,\n",
       "   13,\n",
       "   15,\n",
       "   14,\n",
       "   16,\n",
       "   14,\n",
       "   17,\n",
       "   16,\n",
       "   20,\n",
       "   19,\n",
       "   21,\n",
       "   20,\n",
       "   22,\n",
       "   20,\n",
       "   6,\n",
       "   11]],\n",
       " 'edge_attr': [[0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [1, 0, 1],\n",
       "  [1, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [1, 0, 1],\n",
       "  [1, 0, 1],\n",
       "  [1, 0, 1],\n",
       "  [1, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1]],\n",
       " 'label': '<SELFIES>[C][C][O][C][=Branch1][C][=O][C][=C][C][=C][C][=C][Ring1][=Branch1][Br]</SELFIES>',\n",
       " 'input_mol_string': '<SELFIES> [C][C][I].[O][=C][Branch1][C][O][C][=C][C][=C][C][=C][Ring1][=Branch1][Br].[C][N][Branch1][C][C][C][=O].[O].[O][=C][Branch1][C][O-1][O].[Na+1] </SELFIES><GRAPH><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol></GRAPH>',\n",
       " 'task_subtask_pair': 'forward_reaction_prediction',\n",
       " 'instruction': 'Can you tell me the potential product of a chemical reaction that uses <INPUT> as the reactants and reagents?',\n",
       " 'additional_x': [[5, 0, 4, 5, 3, 0, 2, 0, 0],\n",
       "  [5, 0, 4, 5, 2, 0, 2, 0, 0],\n",
       "  [52, 0, 1, 5, 0, 0, 2, 0, 0],\n",
       "  [7, 0, 1, 5, 0, 0, 1, 0, 0],\n",
       "  [5, 0, 3, 5, 0, 0, 1, 0, 0],\n",
       "  [7, 0, 2, 5, 1, 0, 1, 0, 0],\n",
       "  [5, 0, 3, 5, 0, 0, 1, 1, 1],\n",
       "  [5, 0, 3, 5, 1, 0, 1, 1, 1],\n",
       "  [5, 0, 3, 5, 1, 0, 1, 1, 1],\n",
       "  [5, 0, 3, 5, 1, 0, 1, 1, 1],\n",
       "  [5, 0, 3, 5, 1, 0, 1, 1, 1],\n",
       "  [5, 0, 3, 5, 0, 0, 1, 1, 1],\n",
       "  [34, 0, 1, 5, 0, 0, 2, 0, 0],\n",
       "  [5, 0, 4, 5, 3, 0, 2, 0, 0],\n",
       "  [6, 0, 3, 5, 0, 0, 1, 0, 0],\n",
       "  [5, 0, 4, 5, 3, 0, 2, 0, 0],\n",
       "  [5, 0, 3, 5, 1, 0, 1, 0, 0],\n",
       "  [7, 0, 1, 5, 0, 0, 1, 0, 0],\n",
       "  [7, 0, 2, 5, 2, 0, 2, 0, 0],\n",
       "  [7, 0, 1, 5, 0, 0, 1, 0, 0],\n",
       "  [5, 0, 3, 5, 0, 0, 1, 0, 0],\n",
       "  [7, 0, 1, 4, 0, 0, 1, 0, 0],\n",
       "  [7, 0, 2, 5, 1, 0, 1, 0, 0],\n",
       "  [10, 0, 0, 6, 0, 0, 5, 0, 0]],\n",
       " 'additional_edge_index': [[0,\n",
       "   1,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   4,\n",
       "   5,\n",
       "   4,\n",
       "   6,\n",
       "   6,\n",
       "   7,\n",
       "   7,\n",
       "   8,\n",
       "   8,\n",
       "   9,\n",
       "   9,\n",
       "   10,\n",
       "   10,\n",
       "   11,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   14,\n",
       "   15,\n",
       "   14,\n",
       "   16,\n",
       "   16,\n",
       "   17,\n",
       "   19,\n",
       "   20,\n",
       "   20,\n",
       "   21,\n",
       "   20,\n",
       "   22,\n",
       "   11,\n",
       "   6],\n",
       "  [1,\n",
       "   0,\n",
       "   2,\n",
       "   1,\n",
       "   4,\n",
       "   3,\n",
       "   5,\n",
       "   4,\n",
       "   6,\n",
       "   4,\n",
       "   7,\n",
       "   6,\n",
       "   8,\n",
       "   7,\n",
       "   9,\n",
       "   8,\n",
       "   10,\n",
       "   9,\n",
       "   11,\n",
       "   10,\n",
       "   12,\n",
       "   11,\n",
       "   14,\n",
       "   13,\n",
       "   15,\n",
       "   14,\n",
       "   16,\n",
       "   14,\n",
       "   17,\n",
       "   16,\n",
       "   20,\n",
       "   19,\n",
       "   21,\n",
       "   20,\n",
       "   22,\n",
       "   20,\n",
       "   6,\n",
       "   11]],\n",
       " 'additional_edge_attr': [[0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [1, 0, 1],\n",
       "  [1, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 0],\n",
       "  [0, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [1, 0, 1],\n",
       "  [1, 0, 1],\n",
       "  [1, 0, 1],\n",
       "  [1, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [0, 0, 1],\n",
       "  [3, 0, 1],\n",
       "  [3, 0, 1]],\n",
       " 'task': 'forward_reaction_prediction',\n",
       " 'prompt_text': '<s>[INST] You are a helpful assistant for molecular chemistry, to address tasks including molecular property classification, molecular property regression, chemical reaction prediction, molecule captioning, molecule generation. \\n\\nCan you tell me the potential product of a chemical reaction that uses <SELFIES> [C][C][I].[O][=C][Branch1][C][O][C][=C][C][=C][C][=C][Ring1][=Branch1][Br].[C][N][Branch1][C][C][C][=O].[O].[O][=C][Branch1][C][O-1][O].[Na+1] </SELFIES><GRAPH><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol><mol></GRAPH> as the reactants and reagents? [INST]',\n",
       " 'target_text': '<SELFIES>[C][C][O][C][=Branch1][C][=O][C][=C][C][=C][C][=C][Ring1][=Branch1][Br]</SELFIES> </s>'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9635b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eae8203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MolDA_CHJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
