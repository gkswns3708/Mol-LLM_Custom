{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d639d2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/miniconda3/envs/MolDA_CHJ/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing TRAIN Split...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0904c681902b4e8594faebca89f55c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8c5d0a42674ee2a506f69a9484ffee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering train (> 512 tokens) (num_proc=64):   0%|          | 0/3313489 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Original: 3,313,489\n",
      " - Filtered: 3,303,537\n",
      " - Dropped:  9,952 (0.30%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07e3bf7fc6847c1a18485b2973f31f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/43 shards):   0%|          | 0/3303537 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Success] Saved to: /home/jovyan/CHJ/Mol-LLM_Custom/dataset/train_official/GSAI-ML-LLaDA-8B-Instruct_string+graph_q32_train_512_Truncation\n",
      "\n",
      ">>> Processing VAL Split...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7377953684e84a7fb7bfcae1520bdeb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering val (> 512 tokens) (num_proc=64):   0%|          | 0/35199 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Original: 35,199\n",
      " - Filtered: 35,042\n",
      " - Dropped:  157 (0.45%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db82f009e034460ab5dad8ce51d80731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/35042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Success] Saved to: /home/jovyan/CHJ/Mol-LLM_Custom/dataset/train_official/GSAI-ML-LLaDA-8B-Instruct_string+graph_q32_val_512_Truncation\n",
      "\n",
      ">>> Processing TEST Split...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de0f6720fcf4206b62bdca9512cdd7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering test (> 512 tokens) (num_proc=64):   0%|          | 0/32822 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Original: 32,822\n",
      " - Filtered: 32,595\n",
      " - Dropped:  227 (0.69%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c70030037924bfda88de989809c5e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/32595 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Success] Saved to: /home/jovyan/CHJ/Mol-LLM_Custom/dataset/train_official/GSAI-ML-LLaDA-8B-Instruct_string+graph_q32_test_512_Truncation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# =============================================================================\n",
    "# [설정] 경로 및 변수\n",
    "# =============================================================================\n",
    "MODEL_ID = \"GSAI-ML/LLaDA-8B-Instruct\"\n",
    "NUM_PROC = 64\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "# 입력 경로 (Step 1에서 생성된 최종 클린 데이터셋)\n",
    "INPUT_PATHS = {\n",
    "    \"train\": \"/home/jovyan/CHJ/Mol-LLM_Custom/dataset/train_official/GSAI-ML-LLaDA-8B-Instruct_string+graph_q32_train_FINAL_CLEANED\",\n",
    "    \"val\": \"/home/jovyan/CHJ/Mol-LLM_Custom/dataset/train_official/GSAI-ML-LLaDA-8B-Instruct_string+graph_q32_val_FINAL_CLEANED\",\n",
    "    \"test\": \"/home/jovyan/CHJ/Mol-LLM_Custom/dataset/train_official/GSAI-ML-LLaDA-8B-Instruct_string+graph_q32_test_FINAL_CLEANED\"\n",
    "}\n",
    "\n",
    "# 출력 디렉토리\n",
    "SAVE_DIR = \"/home/jovyan/CHJ/Mol-LLM_Custom/dataset/train_official/\"\n",
    "\n",
    "# SELFIES 사전 경로\n",
    "SELFIES_DICT_PATH = \"/home/jovyan/CHJ/Mol-LLM_Custom/model/selfies_dict.txt\"\n",
    "\n",
    "# =============================================================================\n",
    "# [1] 토크나이저 준비 (Special Tokens 포함)\n",
    "# =============================================================================\n",
    "def get_custom_tokenizer():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "    \n",
    "    # 기본 스페셜 토큰 정의 (이전 코드와 동일)\n",
    "    CUSTOM_SPECIAL_TOKENS = [\n",
    "        \"<BOOLEAN>\", \"</BOOLEAN>\", \"<FLOAT>\", \"</FLOAT>\", \"<DESCRIPTION>\", \"</DESCRIPTION>\",\n",
    "        \"<SELFIES>\", \"</SELFIES>\", \"<GRAPH>\", \"</GRAPH>\", \"<3D_CONFORMER>\", \"</3D_CONFORMER>\",\n",
    "        \"<mol>\", \"<|0|>\", \"<|1|>\", \"<|2|>\", \"<|3|>\", \"<|4|>\", \"<|5|>\", \"<|6|>\", \"<|7|>\", \n",
    "        \"<|8|>\", \"<|9|>\", \"<|+|>\", \"<|-|>\", \"<|.|>\", \"<INSTRUCTION>\", \"</INSTRUCTION>\", \n",
    "        \"|>>|\", \"<IUPAC>\", \"</IUPAC>\", \"<MOLFORMULA>\", \"</MOLFORMULA>\"\n",
    "    ]\n",
    "    \n",
    "    if os.path.exists(SELFIES_DICT_PATH):\n",
    "        with open(SELFIES_DICT_PATH, 'r') as f:\n",
    "            selfies_tokens = [line.strip() for line in f if line.strip()]\n",
    "        CUSTOM_SPECIAL_TOKENS.extend(selfies_tokens)\n",
    "    \n",
    "    tokenizer.add_tokens(list(set(CUSTOM_SPECIAL_TOKENS)))\n",
    "    return tokenizer\n",
    "\n",
    "tokenizer = get_custom_tokenizer()\n",
    "\n",
    "# =============================================================================\n",
    "# [2] 필터링 함수 정의\n",
    "# =============================================================================\n",
    "def filter_by_length(batch):\n",
    "    # Prompt와 Target을 토큰화 (전체 길이를 측정하기 위해 truncation=False)\n",
    "    p_enc = tokenizer(batch['prompt_text'], add_special_tokens=False)\n",
    "    t_enc = tokenizer(batch['target_text'], add_special_tokens=False)\n",
    "    \n",
    "    # 결과 리스트 (각 샘플별로 합산 길이가 512 이하인 것만 True)\n",
    "    keep_indices = []\n",
    "    for p_ids, t_ids in zip(p_enc['input_ids'], t_enc['input_ids']):\n",
    "        # Prompt + Target 길이가 512 이내인지 확인\n",
    "        if len(p_ids) + len(t_ids) <= MAX_LENGTH:\n",
    "            keep_indices.append(True)\n",
    "        else:\n",
    "            keep_indices.append(False)\n",
    "    return keep_indices\n",
    "\n",
    "# =============================================================================\n",
    "# [3] 메인 실행 루프\n",
    "# =============================================================================\n",
    "def run_truncation_pipeline():\n",
    "    for split, path in INPUT_PATHS.items():\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"[Skip] {split} dataset not found at {path}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n>>> Processing {split.upper()} Split...\")\n",
    "        ds = load_from_disk(path)\n",
    "        original_count = len(ds)\n",
    "        \n",
    "        # 필터링 수행\n",
    "        # .filter()의 batched=True를 사용하여 토큰화 속도를 높입니다.\n",
    "        ds_filtered = ds.filter(\n",
    "            filter_by_length,\n",
    "            batched=True,\n",
    "            batch_size=1000,\n",
    "            num_proc=NUM_PROC,\n",
    "            desc=f\"Filtering {split} (> {MAX_LENGTH} tokens)\"\n",
    "        )\n",
    "        \n",
    "        filtered_count = len(ds_filtered)\n",
    "        dropped_count = original_count - filtered_count\n",
    "        \n",
    "        print(f\" - Original: {original_count:,}\")\n",
    "        print(f\" - Filtered: {filtered_count:,}\")\n",
    "        print(f\" - Dropped:  {dropped_count:,} ({ (dropped_count/original_count)*100:.2f}%)\")\n",
    "        \n",
    "        # 저장 경로 생성\n",
    "        # 예: GSAI-ML-LLaDA-8B-Instruct_string+graph_q32_train_512_Truncation\n",
    "        save_name = f\"GSAI-ML-LLaDA-8B-Instruct_string+graph_q32_{split}_512_Truncation\"\n",
    "        save_full_path = os.path.join(SAVE_DIR, save_name)\n",
    "        \n",
    "        ds_filtered.save_to_disk(save_full_path)\n",
    "        print(f\"[Success] Saved to: {save_full_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_truncation_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "945a0220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34adc569bde455290f3f90c3792dfc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Counter({'smol-forward_synthesis': 957064,\n",
       "         'smol-retrosynthesis': 858460,\n",
       "         'smol-name_conversion-i2s': 296011,\n",
       "         'smol-name_conversion-s2i': 295989,\n",
       "         'reagent_prediction': 121846,\n",
       "         'forward_reaction_prediction': 121795,\n",
       "         'retrosynthesis': 120557,\n",
       "         'qm9_lumo': 117708,\n",
       "         'qm9_homo': 117660,\n",
       "         'qm9_homo_lumo_gap': 117539,\n",
       "         'smol-molecule_captioning': 39195,\n",
       "         'smol-property_prediction-hiv': 32864,\n",
       "         'chebi-20-mol2text': 26113,\n",
       "         'chebi-20-text2mol': 25887,\n",
       "         'smol-molecule_generation': 24843,\n",
       "         'smol-property_prediction-sider': 21986,\n",
       "         'smol-property_prediction-lipo': 3341,\n",
       "         'smol-property_prediction-bbbp': 1450,\n",
       "         'bace': 1210,\n",
       "         'smol-property_prediction-clintox': 1131,\n",
       "         'smol-property_prediction-esol': 888})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "from collections import Counter\n",
    "train_ds = load_from_disk('/home/jovyan/CHJ/Mol-LLM_Custom/dataset/train_official/GSAI-ML-LLaDA-8B-Instruct_string+graph_q32_train_512_Truncation')\n",
    "Counter(train_ds['task'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46121703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MolDA_CHJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
