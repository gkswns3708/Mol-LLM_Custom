{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "175f7b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/miniconda3/envs/MolDA_CHJ/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/tmp/ipykernel_3495307/152200540.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(file_path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Checkpoint Keys ===\n",
      "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers', 'hparams_name', 'hyper_parameters', 'hparams_type', 'task_specific_chosen_reward'])\n",
      "\n",
      "=== Hyper Parameters ===\n",
      "{'raw_data_root': '/home/elicer/text-mol/data/data/Mol-LLM-v7.1', 'data_tag': '3.3M_0415_molpo-replace-0.3', 'tasks': ['smol-property_prediction-bbbp', 'smol-property_prediction-clintox', 'smol-property_prediction-hiv', 'smol-property_prediction-sider', 'bace', 'smol-property_prediction-esol', 'smol-property_prediction-lipo', 'qm9_homo', 'qm9_lumo', 'qm9_homo_lumo_gap', 'forward_reaction_prediction', 'smol-forward_synthesis', 'retrosynthesis', 'smol-retrosynthesis', 'reagent_prediction', 'chebi-20-text2mol', 'smol-molecule_generation', 'chebi-20-mol2text', 'smol-molecule_captioning'], 'gnn_type': 'gine_tokengt', 'tune_gnn': True, 'gnn_hidden_dim': 1024, 'gine': {'gnn_hidden_dim': 1024, 'gin_num_layers': 5, 'drop_ratio': 0.0, 'used_gnn_layer': -1, 'gnn_jk': 'last', 'graph_encoder_ckpt': '/home/elicer/text-mol/data/all_checkpoints/Custom_gnn_models/GINE/best-model-5M.ckpt', 'gnn_type': 'gine'}, 'tokengt': {'input_feat_dim': 9, 'gnn_hidden_dim': 1024, 'num_layers': 5, 'num_heads': 8, 'method': 'laplacian', 'd_p': 64, 'd_e': 64, 'use_graph_token': True, 'max_position_embeddings': 102, 'graph_encoder_ckpt': '/home/elicer/text-mol/data/all_checkpoints/Custom_gnn_models/TokenGT/best-model-5M.ckpt', 'gnn_type': 'tokengt'}, 'bert_hidden_dim': 768, 'bert_name': 'scibert', 'cross_attention_freq': 2, 'num_query_token': 32, 'bert_num_hidden_layers': 5, 'projector_type': 'qformer', 'llm_model': 'mistralai/Mistral-7B-Instruct-v0.3', 'tune_llm': 'lora', 'peft_config': None, 'peft_dir': '', 'load_in_8bit': False, 'lora_r': 64, 'lora_alpha': 32, 'lora_dropout': 0.1, 'selfies_token_path': 'Mol-LLM/model/selfies_dict.txt', 'add_selfies_tokens': True, 'prompt': '[START_I_SMILES]{}[END_I_SMILES]', 'num_beams': 1, 'strategy_name': None, 'accelerator': 'gpu', 'devices': '0,1,2,3,4,5,6,7', 'precision': 'bf16-mixed', 'max_steps': -1, 'max_epochs': 6, 'every_n_epochs': 1, 'task': None, 'logging_dir': '/home/elicer/text-mol/data/all_checkpoints', 'llava_pretraining': 0, 'second_stage_start_epoch': 4, 'num_workers': 0, 'skip_sanity_check': True, 'total_batch_size': 2048, 'batch_size': 4, 'inference_batch_size': 8, 'truncation': 1, 'padding': 'max_length', 'max_length': 512, 'gen_max_len': 256, 'min_len': 8, 'apply_sequence_packing': False, 'max_packing_size': -1, 'weight_decay': 0.05, 'min_lr': 1e-05, 'init_lr': 2e-05, 'warmup_lr': 2e-05, 'warmup_epochs': 0.25, 'scheduler': 'linear_warmup_cosine_lr', 'optimizer': 'adamw', 'log_every_n_steps': 50, 'gradient_clip_val': 0.5, 'val_check_interval': 0.2, 'test_on_trainset': False, 'mol_representation': 'string+graph', 'log_attn_score': True, 'eval_modality_util': None, 'train_molpo': True, 'eval_molpo': False, 'shuffle_graph_feature': False, 'molpo_batch_division': 2, 'beta': 1.0, 'gamma_beta_ratio': 0.5, 'sft_weight': 1.0, 'molpo_weight': 0.25, 'anc_rejected_weight': 0.0, 'anc_reject_clip': -1, 'rejected_lambda': 1.5, 'molpo_lambda': -0.5, 'margin_clip_scale': 1.0, 'reject_label_mask': False, 'apply_preference_system_prompt': False, 'selfies_enumeration': False, 'loss_type': 'sigmoid', 'anc_loss_type': 'sigmoid', 'find_unused_parameters': True, 'filename': 'MT_from-string_only_12ep_molpo-wo-L-rej-margin_clip_scale-1.0_6ep_0502_continue', 'seed': 42, 'mode': 'ft', 'wandb_entity': 'mol-llm', 'wandb_project': 'mol-llm', 'wandb_log_freq': 100, 'wandb_id': None, 'debug': False, 'ckpt_path': None, 'pretrained_ckpt_path': '/home/elicer/text-mol/data/all_checkpoints/MT_from-string_only_12ep_molpo-wo-L-rej-margin_clip_scale-1.0_6ep_0502/epoch=05-step=9689.ckpt', 'shuffle_selfies': False, 'shuffle_graph': False, 'process_disjoint': True, 'current_epoch': 0, 'accumulate_grad_batches': 64}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 파일 경로 설정\n",
    "file_path = \"//home/jovyan/CHJ/Mol-LLM_Custom/checkpoint/Custom/mol-llm.ckpt\"\n",
    "\n",
    "# 체크포인트 로드 (CPU로 매핑하여 메모리 부하 방지)\n",
    "# 주의: LLM 모델 체크포인트는 용량이 클 수 있으므로 시스템 RAM을 확인하세요.\n",
    "checkpoint = torch.load(file_path, map_location='cpu')\n",
    "\n",
    "# 최상위 Key 출력\n",
    "print(\"=== Checkpoint Keys ===\")\n",
    "print(checkpoint.keys())\n",
    "\n",
    "# (선택) 하이퍼파라미터가 저장되어 있는지 확인\n",
    "if 'hyper_parameters' in checkpoint:\n",
    "    print(\"\\n=== Hyper Parameters ===\")\n",
    "    print(checkpoint['hyper_parameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5f70937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['blip2model.query_tokens', 'blip2model.llm_model.base_model.model.model.embed_tokens.weight', 'blip2model.llm_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight', 'blip2model.llm_model.base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight', 'blip2model.llm_model.base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight', 'blip2model.graph_encoder.graph_encoder_gine.atom_encoder.atom_embedding_list.0.weight', 'blip2model.graph_encoder.graph_encoder_gine.atom_encoder.atom_embedding_list.1.weight', 'blip2model.graph_encoder.graph_encoder_gine.atom_encoder.atom_embedding_list.2.weight', 'blip2model.graph_encoder.graph_encoder_gine.atom_encoder.atom_embedding_list.3.weight', 'blip2model.graph_encoder.graph_encoder_gine.atom_encoder.atom_embedding_list.4.weight', 'blip2model.graph_encoder.graph_encoder_gine.atom_encoder.atom_embedding_list.5.weight', 'blip2model.graph_encoder.graph_encoder_gine.atom_encoder.atom_embedding_list.6.weight', 'blip2model.graph_encoder.graph_encoder_gine.atom_encoder.atom_embedding_list.7.weight', 'blip2model.graph_encoder.graph_encoder_gine.atom_encoder.atom_embedding_list.8.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.0.eps', 'blip2model.graph_encoder.graph_encoder_gine.gnns.0.mlp.0.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.0.mlp.0.bias', 'blip2model.graph_encoder.graph_encoder_gine.gnns.0.mlp.1.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.0.mlp.1.bias', 'blip2model.graph_encoder.graph_encoder_gine.gnns.0.mlp.1.running_mean', 'blip2model.graph_encoder.graph_encoder_gine.gnns.0.mlp.1.running_var', 'blip2model.graph_encoder.graph_encoder_gine.gnns.0.mlp.1.num_batches_tracked', 'blip2model.graph_encoder.graph_encoder_gine.gnns.0.mlp.3.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.0.mlp.3.bias', 'blip2model.graph_encoder.graph_encoder_gine.gnns.0.bond_encoder.bond_embedding_list.0.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.0.bond_encoder.bond_embedding_list.1.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.0.bond_encoder.bond_embedding_list.2.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.1.eps', 'blip2model.graph_encoder.graph_encoder_gine.gnns.1.mlp.0.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.1.mlp.0.bias', 'blip2model.graph_encoder.graph_encoder_gine.gnns.1.mlp.1.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.1.mlp.1.bias', 'blip2model.graph_encoder.graph_encoder_gine.gnns.1.mlp.1.running_mean', 'blip2model.graph_encoder.graph_encoder_gine.gnns.1.mlp.1.running_var', 'blip2model.graph_encoder.graph_encoder_gine.gnns.1.mlp.1.num_batches_tracked', 'blip2model.graph_encoder.graph_encoder_gine.gnns.1.mlp.3.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.1.mlp.3.bias', 'blip2model.graph_encoder.graph_encoder_gine.gnns.1.bond_encoder.bond_embedding_list.0.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.1.bond_encoder.bond_embedding_list.1.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.1.bond_encoder.bond_embedding_list.2.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.2.eps', 'blip2model.graph_encoder.graph_encoder_gine.gnns.2.mlp.0.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.2.mlp.0.bias', 'blip2model.graph_encoder.graph_encoder_gine.gnns.2.mlp.1.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.2.mlp.1.bias', 'blip2model.graph_encoder.graph_encoder_gine.gnns.2.mlp.1.running_mean', 'blip2model.graph_encoder.graph_encoder_gine.gnns.2.mlp.1.running_var', 'blip2model.graph_encoder.graph_encoder_gine.gnns.2.mlp.1.num_batches_tracked', 'blip2model.graph_encoder.graph_encoder_gine.gnns.2.mlp.3.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.2.mlp.3.bias', 'blip2model.graph_encoder.graph_encoder_gine.gnns.2.bond_encoder.bond_embedding_list.0.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.2.bond_encoder.bond_embedding_list.1.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.2.bond_encoder.bond_embedding_list.2.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.3.eps', 'blip2model.graph_encoder.graph_encoder_gine.gnns.3.mlp.0.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.3.mlp.0.bias', 'blip2model.graph_encoder.graph_encoder_gine.gnns.3.mlp.1.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.3.mlp.1.bias', 'blip2model.graph_encoder.graph_encoder_gine.gnns.3.mlp.1.running_mean', 'blip2model.graph_encoder.graph_encoder_gine.gnns.3.mlp.1.running_var', 'blip2model.graph_encoder.graph_encoder_gine.gnns.3.mlp.1.num_batches_tracked', 'blip2model.graph_encoder.graph_encoder_gine.gnns.3.mlp.3.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.3.mlp.3.bias', 'blip2model.graph_encoder.graph_encoder_gine.gnns.3.bond_encoder.bond_embedding_list.0.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.3.bond_encoder.bond_embedding_list.1.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.3.bond_encoder.bond_embedding_list.2.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.4.eps', 'blip2model.graph_encoder.graph_encoder_gine.gnns.4.mlp.0.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.4.mlp.0.bias', 'blip2model.graph_encoder.graph_encoder_gine.gnns.4.mlp.1.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.4.mlp.1.bias', 'blip2model.graph_encoder.graph_encoder_gine.gnns.4.mlp.1.running_mean', 'blip2model.graph_encoder.graph_encoder_gine.gnns.4.mlp.1.running_var', 'blip2model.graph_encoder.graph_encoder_gine.gnns.4.mlp.1.num_batches_tracked', 'blip2model.graph_encoder.graph_encoder_gine.gnns.4.mlp.3.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.4.mlp.3.bias', 'blip2model.graph_encoder.graph_encoder_gine.gnns.4.bond_encoder.bond_embedding_list.0.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.4.bond_encoder.bond_embedding_list.1.weight', 'blip2model.graph_encoder.graph_encoder_gine.gnns.4.bond_encoder.bond_embedding_list.2.weight', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.0.weight', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.0.bias', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.0.running_mean', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.0.running_var', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.0.num_batches_tracked', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.1.weight', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.1.bias', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.1.running_mean', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.1.running_var', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.1.num_batches_tracked', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.2.weight', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.2.bias', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.2.running_mean', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.2.running_var', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.2.num_batches_tracked', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.3.weight', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.3.bias', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.3.running_mean', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.3.running_var', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.3.num_batches_tracked', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.4.weight', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.4.bias', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.4.running_mean', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.4.running_var', 'blip2model.graph_encoder.graph_encoder_gine.batch_norms.4.num_batches_tracked', 'blip2model.graph_encoder.graph_encoder_tokengt.tokenizer.E_V', 'blip2model.graph_encoder.graph_encoder_tokengt.tokenizer.E_E', 'blip2model.graph_encoder.graph_encoder_tokengt.tokenizer.graph_token', 'blip2model.graph_encoder.graph_encoder_tokengt.tokenizer.edge_proj.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.tokenizer.edge_proj.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.tokenizer.w_in.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.tokenizer.w_in.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.0.mixer.Wqkv.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.0.mixer.Wqkv.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.0.mixer.out_proj.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.0.mixer.out_proj.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.0.norm1.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.0.norm1.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.0.mlp.fc1.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.0.mlp.fc1.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.0.mlp.fc2.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.0.mlp.fc2.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.0.norm2.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.0.norm2.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.1.mixer.Wqkv.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.1.mixer.Wqkv.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.1.mixer.out_proj.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.1.mixer.out_proj.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.1.norm1.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.1.norm1.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.1.mlp.fc1.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.1.mlp.fc1.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.1.mlp.fc2.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.1.mlp.fc2.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.1.norm2.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.1.norm2.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.2.mixer.Wqkv.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.2.mixer.Wqkv.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.2.mixer.out_proj.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.2.mixer.out_proj.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.2.norm1.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.2.norm1.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.2.mlp.fc1.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.2.mlp.fc1.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.2.mlp.fc2.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.2.mlp.fc2.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.2.norm2.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.2.norm2.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.3.mixer.Wqkv.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.3.mixer.Wqkv.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.3.mixer.out_proj.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.3.mixer.out_proj.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.3.norm1.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.3.norm1.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.3.mlp.fc1.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.3.mlp.fc1.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.3.mlp.fc2.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.3.mlp.fc2.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.3.norm2.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.3.norm2.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.4.mixer.Wqkv.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.4.mixer.Wqkv.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.4.mixer.out_proj.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.4.mixer.out_proj.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.4.norm1.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.4.norm1.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.4.mlp.fc1.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.4.mlp.fc1.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.4.mlp.fc2.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.4.mlp.fc2.bias', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.4.norm2.weight', 'blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.4.norm2.bias', 'blip2model.graph_encoder.layer_norm_gine.weight', 'blip2model.graph_encoder.layer_norm_gine.bias', 'blip2model.graph_encoder.layer_norm_tokengt.weight', 'blip2model.graph_encoder.layer_norm_tokengt.bias', 'blip2model.ln_graph.weight', 'blip2model.ln_graph.bias', 'blip2model.Qformer.bert.embeddings.LayerNorm.weight', 'blip2model.Qformer.bert.embeddings.LayerNorm.bias', 'blip2model.Qformer.bert.encoder.layer.0.attention.self.query.weight', 'blip2model.Qformer.bert.encoder.layer.0.attention.self.query.bias', 'blip2model.Qformer.bert.encoder.layer.0.attention.self.key.weight', 'blip2model.Qformer.bert.encoder.layer.0.attention.self.key.bias', 'blip2model.Qformer.bert.encoder.layer.0.attention.self.value.weight', 'blip2model.Qformer.bert.encoder.layer.0.attention.self.value.bias', 'blip2model.Qformer.bert.encoder.layer.0.attention.output.dense.weight', 'blip2model.Qformer.bert.encoder.layer.0.attention.output.dense.bias', 'blip2model.Qformer.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'blip2model.Qformer.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'blip2model.Qformer.bert.encoder.layer.0.crossattention.self.query.weight', 'blip2model.Qformer.bert.encoder.layer.0.crossattention.self.query.bias', 'blip2model.Qformer.bert.encoder.layer.0.crossattention.self.key.weight', 'blip2model.Qformer.bert.encoder.layer.0.crossattention.self.key.bias', 'blip2model.Qformer.bert.encoder.layer.0.crossattention.self.value.weight', 'blip2model.Qformer.bert.encoder.layer.0.crossattention.self.value.bias', 'blip2model.Qformer.bert.encoder.layer.0.crossattention.output.dense.weight', 'blip2model.Qformer.bert.encoder.layer.0.crossattention.output.dense.bias', 'blip2model.Qformer.bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'blip2model.Qformer.bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'blip2model.Qformer.bert.encoder.layer.0.intermediate_query.dense.weight', 'blip2model.Qformer.bert.encoder.layer.0.intermediate_query.dense.bias', 'blip2model.Qformer.bert.encoder.layer.0.output_query.dense.weight', 'blip2model.Qformer.bert.encoder.layer.0.output_query.dense.bias', 'blip2model.Qformer.bert.encoder.layer.0.output_query.LayerNorm.weight', 'blip2model.Qformer.bert.encoder.layer.0.output_query.LayerNorm.bias', 'blip2model.Qformer.bert.encoder.layer.1.attention.self.query.weight', 'blip2model.Qformer.bert.encoder.layer.1.attention.self.query.bias', 'blip2model.Qformer.bert.encoder.layer.1.attention.self.key.weight', 'blip2model.Qformer.bert.encoder.layer.1.attention.self.key.bias', 'blip2model.Qformer.bert.encoder.layer.1.attention.self.value.weight', 'blip2model.Qformer.bert.encoder.layer.1.attention.self.value.bias', 'blip2model.Qformer.bert.encoder.layer.1.attention.output.dense.weight', 'blip2model.Qformer.bert.encoder.layer.1.attention.output.dense.bias', 'blip2model.Qformer.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'blip2model.Qformer.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'blip2model.Qformer.bert.encoder.layer.1.intermediate_query.dense.weight', 'blip2model.Qformer.bert.encoder.layer.1.intermediate_query.dense.bias', 'blip2model.Qformer.bert.encoder.layer.1.output_query.dense.weight', 'blip2model.Qformer.bert.encoder.layer.1.output_query.dense.bias', 'blip2model.Qformer.bert.encoder.layer.1.output_query.LayerNorm.weight', 'blip2model.Qformer.bert.encoder.layer.1.output_query.LayerNorm.bias', 'blip2model.Qformer.bert.encoder.layer.2.attention.self.query.weight', 'blip2model.Qformer.bert.encoder.layer.2.attention.self.query.bias', 'blip2model.Qformer.bert.encoder.layer.2.attention.self.key.weight', 'blip2model.Qformer.bert.encoder.layer.2.attention.self.key.bias', 'blip2model.Qformer.bert.encoder.layer.2.attention.self.value.weight', 'blip2model.Qformer.bert.encoder.layer.2.attention.self.value.bias', 'blip2model.Qformer.bert.encoder.layer.2.attention.output.dense.weight', 'blip2model.Qformer.bert.encoder.layer.2.attention.output.dense.bias', 'blip2model.Qformer.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'blip2model.Qformer.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'blip2model.Qformer.bert.encoder.layer.2.crossattention.self.query.weight', 'blip2model.Qformer.bert.encoder.layer.2.crossattention.self.query.bias', 'blip2model.Qformer.bert.encoder.layer.2.crossattention.self.key.weight', 'blip2model.Qformer.bert.encoder.layer.2.crossattention.self.key.bias', 'blip2model.Qformer.bert.encoder.layer.2.crossattention.self.value.weight', 'blip2model.Qformer.bert.encoder.layer.2.crossattention.self.value.bias', 'blip2model.Qformer.bert.encoder.layer.2.crossattention.output.dense.weight', 'blip2model.Qformer.bert.encoder.layer.2.crossattention.output.dense.bias', 'blip2model.Qformer.bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'blip2model.Qformer.bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'blip2model.Qformer.bert.encoder.layer.2.intermediate_query.dense.weight', 'blip2model.Qformer.bert.encoder.layer.2.intermediate_query.dense.bias', 'blip2model.Qformer.bert.encoder.layer.2.output_query.dense.weight', 'blip2model.Qformer.bert.encoder.layer.2.output_query.dense.bias', 'blip2model.Qformer.bert.encoder.layer.2.output_query.LayerNorm.weight', 'blip2model.Qformer.bert.encoder.layer.2.output_query.LayerNorm.bias', 'blip2model.Qformer.bert.encoder.layer.3.attention.self.query.weight', 'blip2model.Qformer.bert.encoder.layer.3.attention.self.query.bias', 'blip2model.Qformer.bert.encoder.layer.3.attention.self.key.weight', 'blip2model.Qformer.bert.encoder.layer.3.attention.self.key.bias', 'blip2model.Qformer.bert.encoder.layer.3.attention.self.value.weight', 'blip2model.Qformer.bert.encoder.layer.3.attention.self.value.bias', 'blip2model.Qformer.bert.encoder.layer.3.attention.output.dense.weight', 'blip2model.Qformer.bert.encoder.layer.3.attention.output.dense.bias', 'blip2model.Qformer.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'blip2model.Qformer.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'blip2model.Qformer.bert.encoder.layer.3.intermediate_query.dense.weight', 'blip2model.Qformer.bert.encoder.layer.3.intermediate_query.dense.bias', 'blip2model.Qformer.bert.encoder.layer.3.output_query.dense.weight', 'blip2model.Qformer.bert.encoder.layer.3.output_query.dense.bias', 'blip2model.Qformer.bert.encoder.layer.3.output_query.LayerNorm.weight', 'blip2model.Qformer.bert.encoder.layer.3.output_query.LayerNorm.bias', 'blip2model.Qformer.bert.encoder.layer.4.attention.self.query.weight', 'blip2model.Qformer.bert.encoder.layer.4.attention.self.query.bias', 'blip2model.Qformer.bert.encoder.layer.4.attention.self.key.weight', 'blip2model.Qformer.bert.encoder.layer.4.attention.self.key.bias', 'blip2model.Qformer.bert.encoder.layer.4.attention.self.value.weight', 'blip2model.Qformer.bert.encoder.layer.4.attention.self.value.bias', 'blip2model.Qformer.bert.encoder.layer.4.attention.output.dense.weight', 'blip2model.Qformer.bert.encoder.layer.4.attention.output.dense.bias', 'blip2model.Qformer.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'blip2model.Qformer.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'blip2model.Qformer.bert.encoder.layer.4.crossattention.self.query.weight', 'blip2model.Qformer.bert.encoder.layer.4.crossattention.self.query.bias', 'blip2model.Qformer.bert.encoder.layer.4.crossattention.self.key.weight', 'blip2model.Qformer.bert.encoder.layer.4.crossattention.self.key.bias', 'blip2model.Qformer.bert.encoder.layer.4.crossattention.self.value.weight', 'blip2model.Qformer.bert.encoder.layer.4.crossattention.self.value.bias', 'blip2model.Qformer.bert.encoder.layer.4.crossattention.output.dense.weight', 'blip2model.Qformer.bert.encoder.layer.4.crossattention.output.dense.bias', 'blip2model.Qformer.bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'blip2model.Qformer.bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'blip2model.Qformer.bert.encoder.layer.4.intermediate_query.dense.weight', 'blip2model.Qformer.bert.encoder.layer.4.intermediate_query.dense.bias', 'blip2model.Qformer.bert.encoder.layer.4.output_query.dense.weight', 'blip2model.Qformer.bert.encoder.layer.4.output_query.dense.bias', 'blip2model.Qformer.bert.encoder.layer.4.output_query.LayerNorm.weight', 'blip2model.Qformer.bert.encoder.layer.4.output_query.LayerNorm.bias', 'blip2model.opt_proj.weight', 'blip2model.opt_proj.bias'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights = checkpoint['state_dict']\n",
    "\n",
    "model_weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fea114d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classifier Layer 후보 검색 결과 ===\n",
      "blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.0.mlp.fc1.weight\n",
      "blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.0.mlp.fc1.bias\n",
      "blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.0.mlp.fc2.weight\n",
      "blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.0.mlp.fc2.bias\n",
      "blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.1.mlp.fc1.weight\n",
      "blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.1.mlp.fc1.bias\n",
      "blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.1.mlp.fc2.weight\n",
      "blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.1.mlp.fc2.bias\n",
      "blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.2.mlp.fc1.weight\n",
      "blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.2.mlp.fc1.bias\n",
      "blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.2.mlp.fc2.weight\n",
      "blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.2.mlp.fc2.bias\n",
      "blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.3.mlp.fc1.weight\n",
      "blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.3.mlp.fc1.bias\n",
      "blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.3.mlp.fc2.weight\n",
      "blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.3.mlp.fc2.bias\n",
      "blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.4.mlp.fc1.weight\n",
      "blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.4.mlp.fc1.bias\n",
      "blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.4.mlp.fc2.weight\n",
      "blip2model.graph_encoder.graph_encoder_tokengt.encoder.layers.4.mlp.fc2.bias\n",
      "blip2model.Qformer.bert.encoder.layer.0.attention.output.dense.weight\n",
      "blip2model.Qformer.bert.encoder.layer.0.attention.output.dense.bias\n",
      "blip2model.Qformer.bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "blip2model.Qformer.bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "blip2model.Qformer.bert.encoder.layer.0.crossattention.output.dense.weight\n",
      "blip2model.Qformer.bert.encoder.layer.0.crossattention.output.dense.bias\n",
      "blip2model.Qformer.bert.encoder.layer.0.crossattention.output.LayerNorm.weight\n",
      "blip2model.Qformer.bert.encoder.layer.0.crossattention.output.LayerNorm.bias\n",
      "blip2model.Qformer.bert.encoder.layer.0.output_query.dense.weight\n",
      "blip2model.Qformer.bert.encoder.layer.0.output_query.dense.bias\n",
      "blip2model.Qformer.bert.encoder.layer.0.output_query.LayerNorm.weight\n",
      "blip2model.Qformer.bert.encoder.layer.0.output_query.LayerNorm.bias\n",
      "blip2model.Qformer.bert.encoder.layer.1.attention.output.dense.weight\n",
      "blip2model.Qformer.bert.encoder.layer.1.attention.output.dense.bias\n",
      "blip2model.Qformer.bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "blip2model.Qformer.bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "blip2model.Qformer.bert.encoder.layer.1.output_query.dense.weight\n",
      "blip2model.Qformer.bert.encoder.layer.1.output_query.dense.bias\n",
      "blip2model.Qformer.bert.encoder.layer.1.output_query.LayerNorm.weight\n",
      "blip2model.Qformer.bert.encoder.layer.1.output_query.LayerNorm.bias\n",
      "blip2model.Qformer.bert.encoder.layer.2.attention.output.dense.weight\n",
      "blip2model.Qformer.bert.encoder.layer.2.attention.output.dense.bias\n",
      "blip2model.Qformer.bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "blip2model.Qformer.bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "blip2model.Qformer.bert.encoder.layer.2.crossattention.output.dense.weight\n",
      "blip2model.Qformer.bert.encoder.layer.2.crossattention.output.dense.bias\n",
      "blip2model.Qformer.bert.encoder.layer.2.crossattention.output.LayerNorm.weight\n",
      "blip2model.Qformer.bert.encoder.layer.2.crossattention.output.LayerNorm.bias\n",
      "blip2model.Qformer.bert.encoder.layer.2.output_query.dense.weight\n",
      "blip2model.Qformer.bert.encoder.layer.2.output_query.dense.bias\n",
      "blip2model.Qformer.bert.encoder.layer.2.output_query.LayerNorm.weight\n",
      "blip2model.Qformer.bert.encoder.layer.2.output_query.LayerNorm.bias\n",
      "blip2model.Qformer.bert.encoder.layer.3.attention.output.dense.weight\n",
      "blip2model.Qformer.bert.encoder.layer.3.attention.output.dense.bias\n",
      "blip2model.Qformer.bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "blip2model.Qformer.bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "blip2model.Qformer.bert.encoder.layer.3.output_query.dense.weight\n",
      "blip2model.Qformer.bert.encoder.layer.3.output_query.dense.bias\n",
      "blip2model.Qformer.bert.encoder.layer.3.output_query.LayerNorm.weight\n",
      "blip2model.Qformer.bert.encoder.layer.3.output_query.LayerNorm.bias\n",
      "blip2model.Qformer.bert.encoder.layer.4.attention.output.dense.weight\n",
      "blip2model.Qformer.bert.encoder.layer.4.attention.output.dense.bias\n",
      "blip2model.Qformer.bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "blip2model.Qformer.bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "blip2model.Qformer.bert.encoder.layer.4.crossattention.output.dense.weight\n",
      "blip2model.Qformer.bert.encoder.layer.4.crossattention.output.dense.bias\n",
      "blip2model.Qformer.bert.encoder.layer.4.crossattention.output.LayerNorm.weight\n",
      "blip2model.Qformer.bert.encoder.layer.4.crossattention.output.LayerNorm.bias\n",
      "blip2model.Qformer.bert.encoder.layer.4.output_query.dense.weight\n",
      "blip2model.Qformer.bert.encoder.layer.4.output_query.dense.bias\n",
      "blip2model.Qformer.bert.encoder.layer.4.output_query.LayerNorm.weight\n",
      "blip2model.Qformer.bert.encoder.layer.4.output_query.LayerNorm.bias\n"
     ]
    }
   ],
   "source": [
    "# 찾고 싶은 키워드 리스트\n",
    "search_keywords = ['head', 'classifier', 'output', 'fc', 'linear']\n",
    "\n",
    "print(\"=== Classifier Layer 후보 검색 결과 ===\")\n",
    "for key in model_weights.keys():\n",
    "    # 키워드 중 하나라도 포함되어 있으면 출력\n",
    "    if any(keyword in key for keyword in search_keywords):\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df23850b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 마지막 레이어들 ===\n",
      "['blip2model.Qformer.bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'blip2model.Qformer.bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'blip2model.Qformer.bert.encoder.layer.4.intermediate_query.dense.weight', 'blip2model.Qformer.bert.encoder.layer.4.intermediate_query.dense.bias', 'blip2model.Qformer.bert.encoder.layer.4.output_query.dense.weight', 'blip2model.Qformer.bert.encoder.layer.4.output_query.dense.bias', 'blip2model.Qformer.bert.encoder.layer.4.output_query.LayerNorm.weight', 'blip2model.Qformer.bert.encoder.layer.4.output_query.LayerNorm.bias', 'blip2model.opt_proj.weight', 'blip2model.opt_proj.bias']\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 마지막 레이어들 ===\")\n",
    "print(list(model_weights.keys())[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a94c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MolDA_CHJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
